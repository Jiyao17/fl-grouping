tuj90887@gpu:~/fl-grouping$ export CUDA_VISIBLE_DEVICES=1
tuj90887@gpu:~/fl-grouping$ python3 test.py

Files already downloaded and verified
Files already downloaded and verified
[  0   0 300   0   0   0   0   0   0 700]
Number of data on selected clients: 20000
[10.77897712 11.07443601 11.29602489 10.64544871 11.07443601 11.29602489
 10.77897712 10.59665973 10.8685875  10.77897712]
lr: 1.000000 -> 0.100000
Traceback (most recent call last):
  File "test.py", line 214, in <module>
    gfl.train()
  File "/home/tuj90887/fl-grouping/utils/fed.py", line 249, in train
    accu, loss = test_model(self.model, self.testloader, self.config.device)
  File "/home/tuj90887/fl-grouping/utils/model.py", line 109, in test_model
    pred = model(samples.to(device))
  File "/home/tuj90887/fl-grouping/python/lib/python3.6/site-packages/torch/nn/modules/module.py"
, line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/tuj90887/fl-grouping/utils/model.py", line 63, in forward
    x = self.convs(x)
  File "/home/tuj90887/fl-grouping/python/lib/python3.6/site-packages/torch/nn/modules/module.py"
, line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/tuj90887/fl-grouping/python/lib/python3.6/site-packages/torch/nn/modules/container.
py", line 141, in forward
    input = module(input)
  File "/home/tuj90887/fl-grouping/python/lib/python3.6/site-packages/torch/nn/modules/module.py"
, line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/tuj90887/fl-grouping/utils/model.py", line 27, in forward
    y = self.bn2(y)
  File "/home/tuj90887/fl-grouping/python/lib/python3.6/site-packages/torch/nn/modules/module.py"
, line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/tuj90887/fl-grouping/python/lib/python3.6/site-packages/torch/nn/modules/batchnorm.
py", line 179, in forward
    self.eps,
  File "/home/tuj90887/fl-grouping/python/lib/python3.6/site-packages/torch/nn/functional.py", li
ne 2283, in batch_norm
    input, weight, bias, running_mean, running_var, training, momentum, eps, torch.backends.cudnn
.enabled
RuntimeError: CUDA out of memory. Tried to allocate 64.00 MiB (GPU 0; 15.78 GiB total capacity; 9
62.21 MiB already allocated; 31.19 MiB free; 978.00 MiB reserved in total by PyTorch) If reserved
 memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documen
tation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
tuj90887@gpu:~/fl-grouping$


config:{'task_name': <TaskName.CIFAR: 1>, 'server_num': 3, 'client_num': 300, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000.0, 'global_epoch_num': 1000, 'group_epoch_num': 10, 'local_epoch_num': 2, 'regroup_interval': 50, 'lr_interval': 1000, 'lr': 0.01, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.PROB_RCV: 1>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.CV_GREEDY: 3>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/cvg_cvs/', 'test_mark': '_rgr50_100_rcv', 'comment': ''}

config:{'task_name': <TaskName.CIFAR: 1>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000.0, 'global_epoch_num': 1000, 'group_epoch_num': 10, 'local_epoch_num': 2, 'regroup_interval': 50, 'lr_interval': 1000, 'lr': 0.01, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.PROB_RCV: 1>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.CV_GREEDY: 3>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/cvg_cvs/', 'test_mark': '_rgr50_100_rcv', 'comment': ''}
0.1016 0.2487 0.2945 0.2947 0.4095 0.4458 0.4001 0.4489 0.5108 0.4838 0.4713 0.4966 0.5471 0.5794 0.599 0.5041 0.5147 0.5608 0.5628 0.5975 0.5784 0.6134 0.6502 0.6206 0.5806 0.6564 0.5912 0.6396 0.5968 0.6515 0.5789 0.6354 0.5992 0.65 0.6562 0.6731 0.6516 0.6747 0.6827 0.6679 0.6941 0.6285 0.6964 0.6463 0.682 0.6935 0.6898 0.6768 0.6792 0.7106 0.7114 0.708 0.7062 0.6925 0.7078 0.6828 0.7145 0.7187 0.7122 0.7166 0.723 0.709 0.691 0.6598 0.6914 0.729 0.7231 0.7072 0.7167 0.6937 0.7197 0.7317 0.7275 0.7168 0.734 0.7141 0.7203 0.7248 0.7163 0.733 0.6727 0.7145 0.6986 0.7199 0.7271 0.7224 0.7315 0.7389 0.733 0.7294 0.7289 0.7364 0.717 0.7289 0.741 0.7456 0.7386 0.7391 0.7326 0.733 0.7451 0.7187 0.7348 0.7359 0.7529 0.744 0.7276 0.7537 0.683 0.739 0.7214 0.7055 0.7484 0.7637 0.7429 0.7467 0.7511 0.7632 0.7248 0.7518 0.7448 0.7501 0.7423 0.7224 0.7496 0.752 0.7113 0.7517 0.7555 0.7507 0.748 0.6834 0.7467 0.763 0.7653 0.7598 0.7503 0.7559 0.7315 0.7329 0.7254 0.6974 0.6758 0.7505 0.731 0.7525 0.7551 0.7538 0.7434 0.7524 0.741 0.7021 0.7621 0.7446 0.7768 0.766 0.7506 0.7444 0.7615 0.7574 0.7373 0.767 0.7686 0.7564 0.7628 0.7554 0.7723 0.7637 0.7439 0.7263 0.7551 0.7717 0.7475 0.7474 0.7554 0.7615 0.7729 0.7264 0.7317 0.7735 0.7659 0.771 0.7683 0.7769 0.7502 0.7655 0.7612 0.7498 0.7828 0.7734 0.7707 0.7719 0.7376 0.7719 0.7669 0.7622 0.7747 0.7542 0.7749 0.7632 0.7523 0.7212 0.7531 0.7518 0.7609 0.7788 0.7529 0.7595 0.7601 0.7642 0.7522 0.7663 0.7665 0.7651 0.7818 0.7632 0.7736 0.7632 0.7678 0.7627 0.7645 0.783 0.7731 0.7511 0.7547 0.7648 0.7766 0.7727 0.7661 0.7495 0.7781 0.7639 0.7415 0.7454 0.7755 0.7613 0.7645 0.739 0.7733 0.7729 0.7681 0.7528 0.7659 0.7679 0.7478 0.7725 0.7781 0.7573 0.7779 0.7738 0.7705 0.7768 0.7777 0.7607 0.7868 0.7836 0.7873 0.7841 0.7798 0.7845 0.7733 0.7775 0.7762 0.7749 0.7628 0.7816 0.7768 0.7645 0.7544 0.7819 0.7298 0.785 0.7854 0.7307 0.7504 0.7569 0.7878 0.7837 0.7733 0.7745 0.7783 0.7787 0.7431 0.7764 0.7675 0.7758 0.7735 0.785 0.7709 0.7622 0.7761 0.7683 0.7779 0.777 0.7643 0.7766 0.7557 0.7518 0.7657 0.7919 0.7835 0.7556 0.7641 0.7854 0.7905 0.768 0.7885 0.7067 0.7674 0.7593 0.769 0.7655 0.7855 0.7866 0.7726 0.7597 0.7761 0.753 0.7829 0.7746 0.762 0.7715 0.748 0.7826 0.7772 0.7783 0.7884 0.7308 0.7805 0.7795 0.7915 0.7798 0.7691 0.7891 0.7526 0.7773 0.7755 0.7655 0.7257 0.7903 0.7783 0.786 0.7734 0.7609 0.7943 0.7865 0.7814 0.7739 0.758 0.7717 0.7811 0.7531 0.7745 0.7817 0.7906 0.7836 0.7713 0.775 0.7713 0.7735 0.7744 0.7833 0.7731 0.7657 0.7801 0.7578 0.7884 0.7715 0.7787 0.7893 0.7817 0.7555 0.7652 0.7655 0.7668 0.7868 0.7743 0.7615 0.7477 0.7775 0.7666 0.7835 0.7863 0.7607 0.7766 0.785 0.7769 0.7644 0.7833 0.7641 0.7693 0.782 0.771 0.7813 0.7671 0.7822 0.7854 0.769 0.7659 0.7884 0.7966 0.7948 0.7464 0.7896 0.7927 0.7935 0.7857 0.7764 0.7968 0.7714 0.7613 0.7461 0.7231 0.7922 0.7833 0.7714 0.7615 0.7903 0.7946 0.773 0.7951 0.762 0.7819 0.7562 0.7872 0.8025 0.7948 0.798 0.7663 0.7783 0.7812 0.7588 0.7686 0.794 0.7942 0.7872 0.8085 0.7935 0.7856 0.799 0.7889 0.7952 0.7485 0.7845 0.7807 0.7701 0.7667 0.7772 0.7812 0.7709 0.7753 0.7824 0.7828 0.7919 0.7936 0.7635 0.7865 0.7868 0.7918 0.7959 0.7993 0.7775 0.7842 0.7883 0.7779 0.7865 0.8 0.7837 0.7555 0.7971 0.7732 0.7664 0.7921 0.7877 0.7792 0.7871 0.7939 0.7857 0.7942 0.7888 0.7928 0.7876 0.7893 0.7726 0.7943 0.7933 0.7727 0.7926 0.7967 0.7832 0.7807 0.7791 0.7862 0.7855 0.7732 0.7708 0.7991 0.7646 0.7844 0.7956 0.7726 0.7966 0.8001 0.7859 0.7972 0.7809 0.8011 0.785 0.779 0.7829 0.7991 0.7872 0.7529 0.7817 0.797 0.7747 0.7877 0.7928 0.7868 0.7867 0.7915 0.7919 0.7909 0.7932 0.7968 0.7648 0.7925 0.7631 0.8007 0.7951 0.7646 0.797 0.7898 0.758 0.7989 0.8018 0.7727 0.7553 0.7877 0.7738 0.7644 0.7848 0.8025 0.7977 0.7901 0.7869 0.7972 0.7938 0.7936 0.7937 0.7986 0.7796 0.7944 0.7926 0.7855 0.7811 0.7222 0.7751 0.8074 0.8007 0.7687 0.8053 0.7953 0.771 0.7875 0.759 0.7701 0.7748 0.7773 0.8022 
config:{'task_name': <TaskName.CIFAR: 1>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000.0, 'global_epoch_num': 1000, 'group_epoch_num': 10, 'local_epoch_num': 2, 'regroup_interval': 50, 'lr_interval': 1000, 'lr': 0.01, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.PROB_RCV: 1>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.CV_GREEDY: 3>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/cvg_cvs/', 'test_mark': '_rgr50_100_rcv', 'comment': ''}
0.0989 0.2427 0.302 0.3498 0.3919 0.3365 0.3633 0.3902 0.4927 0.5069 0.5063 0.5194 0.4746 0.4886 0.5141 0.4507 0.4766 0.5141 0.5669 0.5818 0.5337 0.5344 0.6199 0.6393 0.5934 0.6157 0.5776 0.6258 0.6417 0.5993 0.6462 0.64 0.6484 0.6526 0.6241 0.6269 0.6288 0.6148 0.6649 0.6147 0.618 0.6702 0.6818 0.6109 0.655 0.6793 0.5606 0.6875 0.6666 0.6649 0.7099 0.6878 0.7168 0.6536 0.7202 0.6328 0.6839 0.68 0.701 0.7099 0.6712 0.6325 0.6967 0.7161 0.6846 0.6256 0.6792 0.7249 0.7046 0.7243 0.6977 0.7066 0.7127 0.6525 0.7406 0.7058 0.7346 0.6824 0.698 0.7124 0.7301 0.6833 0.7069 0.7244 0.7087 0.7077 0.7292 0.7096 0.7195 0.7235 0.7282 0.7216 0.6662 0.7311 0.7077 0.7342 0.6992 0.7271 0.7319 0.7435 0.7394 0.751 0.7151 0.7384 0.738 0.7453 0.7197 0.7221 0.7102 0.6833 0.7021 0.7139 0.7423 0.7447 0.7435 0.7532 0.6421 0.7007 0.7059 0.7224 0.7363 0.7586 0.754 0.7482 0.7312 0.7326 0.7588 0.759 0.7491 0.7418 0.7205 0.7433 0.7214 0.7566 0.6718 0.7452 0.7485 0.7461 0.7213 0.7359 0.7411 0.7655 0.7265 0.7335 0.7564 0.7511 0.7612 0.7368 0.7659 0.7453 0.7382 0.7434 0.7342 0.7375 0.7319 0.7138 0.7217 0.7626 0.7381 0.7055 0.749 0.7506 0.7577 0.7482 0.7588 0.7595 0.7555 0.7483 0.7412 0.7001 0.7593 0.7621 0.7283 0.7554 0.7565 0.7468 0.7503 0.763 0.7587 0.7718 0.7609 0.6833 0.7617 0.752 0.76 0.7373 0.6765 0.7563 0.7364 0.7608 0.7594 0.7532 0.7555 0.7496 0.7478 0.74 0.7297 0.7589 0.7519 0.7719 0.7274 0.7623 0.7541 0.7598 0.7478 0.7657 0.7537 0.7494 0.7407 
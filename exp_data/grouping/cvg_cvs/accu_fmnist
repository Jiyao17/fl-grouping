
config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda:2', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.PROB_ESRCV: 4>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.CV_GREEDY: 3>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/cvg_cvs/', 'test_mark': '_fmnist', 'comment': ''}

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda:2', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.PROB_ESRCV: 4>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.CV_GREEDY: 3>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/cvg_cvs/', 'test_mark': '_fmnist', 'comment': ''}

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda:2', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.PROB_ESRCV: 4>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.CV_GREEDY: 3>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/cvg_cvs/', 'test_mark': '_fmnist', 'comment': ''}
0.3551 0.5424 0.613 0.6623 0.715 0.7242 0.7562 0.7458 0.7485 0.7507 0.7658 0.7817 0.783 0.7762 0.786 0.7998 0.7848 0.7782 0.7961 0.8026 0.7981 0.7977 0.792 0.8048 0.7984 0.8018 0.8025 0.8089 0.7949 0.8093 0.796 0.8082 0.7963 0.8156 0.8108 0.8195 0.8059 0.7888 0.7925 0.8178 0.8105 0.8139 0.8188 0.814 0.8029 0.8194 0.8184 0.8082 0.822 0.8104 0.7945 0.8201 0.8321 0.8147 0.8161 0.8247 0.8208 0.8128 0.8238 0.8214 0.8179 0.8222 0.8256 0.821 0.8224 0.8188 0.8208 0.8257 0.8171 0.8293 0.8156 0.8249 0.8288 0.8268 0.8255 0.8249 0.83 0.8276 0.824 0.8204 0.8285 0.8261 0.8336 0.8295 0.8215 0.8278 0.8249 0.8302 0.8289 0.8285 0.8278 0.8305 0.8272 0.8296 0.8298 0.8285 0.8261 0.832 0.8251 0.8144 
config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.PROB_ESRCV: 4>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.CV_GREEDY: 3>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/cvg_cvs/', 'test_mark': '_fmnist', 'comment': ''}

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.PROB_ESRCV: 4>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.CV_GREEDY: 3>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/cvg_cvs/', 'test_mark': '_fmnist', 'comment': ''}
0.3897 0.4984 0.5515 0.562 0.6533 0.6693 0.6798 0.698 0.7106 0.7181 0.7198 0.7255 0.7199 0.7195 0.7297 0.7417 0.7449 0.7496 0.744 0.733 0.7386 0.758 0.73 0.7535 0.7339 0.7483 0.771 0.771 0.754 0.7719 0.7576 0.7743 0.7615 0.7735 0.7692 0.7688 0.7509 0.7492 0.7518 0.7838 0.7825 0.7848 0.772 0.7811 0.7668 0.7845 0.7785 0.7818 0.7827 0.7681 0.7596 0.7697 0.7863 0.778 0.7886 0.7833 0.789 0.7817 0.7748 0.7868 0.7899 0.7898 0.7473 0.7799 0.7808 0.7926 0.7916 0.7815 0.7928 0.7795 0.7903 0.7911 0.7906 0.7897 0.7811 0.7734 0.7897 0.7901 0.7801 0.7875 0.7874 0.7859 0.7952 0.7735 0.7989 0.7945 0.7896 0.7951 0.7952 0.7908 0.785 0.7768 0.7974 0.7938 0.7964 0.7958 0.7894 0.7905 0.7931 0.7965 0.7948 0.7865 0.7965 0.7916 0.8009 0.8036 0.7947 0.7997 0.795 0.7968 0.7954 0.7996 0.7964 0.7965 0.7863 0.7489 0.8068 0.8001 0.7867 0.8018 0.8013 0.8001 0.7942 0.8015 0.7999 0.8004 0.7988 0.7958 0.7803 0.792 0.7998 0.8 0.7928 0.7704 0.801 0.8013 0.7965 0.7968 0.8014 0.7958 0.788 0.7992 0.8008 0.8014 0.7972 0.7914 0.8046 0.7994 0.8029 0.8031 0.7951 0.8057 0.8052 0.7963 0.8014 0.7934 0.802 0.8018 0.8016 0.8011 0.7958 0.7976 0.7987 
config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 101), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.PROB_ESRCV: 4>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.CV_GREEDY: 3>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/cvg_cvs/', 'test_mark': '_fmnist', 'comment': ''}

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 101), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.PROB_ESRCV: 4>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.CV_GREEDY: 3>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/cvg_cvs/', 'test_mark': '_fmnist', 'comment': ''}

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 101), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.PROB_ESRCV: 4>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.CV_GREEDY: 3>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/cvg_cvs/', 'test_mark': '_fmnist', 'comment': ''}
0.2123 0.4018 0.492 0.5255 0.5671 0.5932 0.6453 0.6529 0.6799 0.6785 0.674 0.7174 0.7168 0.6829 0.7231 0.7376 0.6816 0.6799 
config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 101), 'alpha': (0.01, 0.01), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 10, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.PROB_ESRCV: 4>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.CV_GREEDY: 3>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/cvg_cvs/', 'test_mark': '_fmnist', 'comment': ''}
0.1039 0.1929 0.1868 0.2556 0.2218 0.2433 0.2271 0.3659 0.3438 0.5094 0.3181 0.4102 0.3326 0.4841 0.4171 0.3836 0.4293 0.5604 0.4173 0.4051 0.479 0.4469 0.3936 0.3816 0.4402 0.5266 0.4102 0.4048 0.5027 0.4361 0.4539 0.4696 0.4759 0.4971 0.5613 0.5489 0.5589 0.522 0.4411 0.5684 0.5331 0.4334 0.4318 0.3897 0.5846 0.4775 0.4621 0.4844 0.4793 
config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 101), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 10, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.PROB_ESRCV: 4>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.CV_GREEDY: 3>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/cvg_cvs/', 'test_mark': '_fmnist', 'comment': ''}
0.4195 0.5494 0.6055 0.6589 0.6407 0.6611 0.698 0.6946 0.7317 0.7371 
config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 51), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 10, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.PROB_ESRCV: 4>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.CV_GREEDY: 3>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/cvg_cvs/', 'test_mark': '_fmnist', 'comment': ''}
0.2062 0.3906 0.5295 0.5837 0.6349 0.6493 0.6721 0.6821 0.6907 0.6944 0.6965 0.6824 0.6942 0.6941 0.701 0.6958 0.7071 0.7057 0.6977 0.7005 0.6911 0.6919 0.709 0.7086 0.6999 0.6988 0.7012 0.6901 0.6798 0.683 0.7058 0.6867 0.6953 0.6997 0.7026 0.7046 0.7109 0.7074 0.6893 0.7011 0.7032 0.6896 0.6911 0.6888 0.7093 0.7071 0.7021 0.7018 0.7033 0.7071 0.7017 0.6976 0.7033 0.6785 0.6952 0.7056 0.7055 0.7013 0.7082 0.7002 0.7235 0.7033 0.7014 0.7219 0.7169 0.7083 0.6988 0.7203 0.7046 0.7061 0.7183 0.7151 0.7004 0.7137 0.713 0.7152 0.7178 0.7129 0.715 0.7169 0.7225 0.7152 0.7184 0.7159 0.7172 0.7081 0.7143 0.7141 0.719 0.7157 0.7154 0.7232 0.7176 0.7202 0.7234 0.7218 0.7208 0.7216 0.7151 0.7226 0.7169 0.7082 0.7241 0.7183 0.7215 0.7207 0.7166 0.7156 0.7278 0.7248 0.7236 0.7258 0.7228 0.7202 0.7205 0.7184 0.7195 0.7205 0.7132 0.7155 0.7221 0.719 0.723 0.7081 0.7233 0.7221 0.7211 0.7222 0.7185 0.7216 0.7188 0.7217 0.7215 0.7183 0.718 0.7173 0.7215 0.7196 0.7237 0.7249 0.7278 0.7233 0.7134 0.7179 0.7203 0.7305 0.7265 0.7263 0.7271 0.7238 0.7233 0.6711 0.7113 0.7176 0.7216 0.7114 0.7262 0.7202 0.724 0.7093 0.7208 0.7233 0.7266 0.7169 0.7256 0.7227 0.7246 0.723 0.7239 0.7211 0.7223 0.7241 0.7196 0.72 0.7238 0.7259 0.7228 0.7223 0.7222 0.7197 0.7251 0.7172 0.719 0.7233 0.7238 0.7229 0.7228 0.7235 0.7247 0.7098 0.7288 0.7262 0.7278 0.7261 
config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 51), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 10, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.PROB_SRCV: 2>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.CV_GREEDY: 3>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/cvg_cvs/', 'test_mark': '_fmnist', 'comment': ''}
0.1087 0.1264 0.308 0.3639 0.378 0.4032 0.4703 0.5276 0.5817 0.6008 0.5753 0.6375 0.5144 0.6436 0.632 0.5958 0.6137 0.6189 0.5943 0.6306 0.6909 0.6865 0.6835 0.649 0.69 0.6666 0.6881 0.6727 0.6677 0.6953 0.6411 0.6789 0.646 0.6679 0.7087 0.6852 0.6899 0.6988 0.7177 0.7249 0.7243 0.7017 0.7216 0.6812 0.6961 0.7017 0.7019 0.726 0.7154 0.6664 0.706 0.6981 0.716 0.682 0.7129 0.707 0.7425 0.74 0.7215 0.7331 0.7001 0.7287 0.7183 0.6934 0.7224 0.6849 0.7059 0.7351 0.7186 0.6615 0.7151 0.7053 0.7292 0.7097 0.7363 0.7354 0.7004 0.6853 0.7362 0.7265 0.7343 0.7341 0.7417 0.7434 0.746 0.7267 0.748 0.7338 0.7286 0.7265 0.7108 0.7408 0.7224 0.6986 0.7426 0.721 0.7186 0.7238 0.7279 0.7343 0.734 0.7397 0.7216 0.7424 0.7545 0.7428 0.7235 0.7561 0.7387 0.724 0.7357 0.7478 0.7534 0.7516 0.7497 0.7193 0.7417 0.7529 0.7219 0.7253 0.7457 0.7444 0.7465 0.7393 0.7452 0.7484 0.7426 0.7326 0.7445 0.7274 0.7396 0.7227 0.7431 0.7442 0.7449 0.7266 0.7325 0.7408 0.7297 0.7446 0.7368 0.7546 0.7613 0.7509 0.7592 0.7335 0.7083 0.7374 0.7515 0.7472 0.7503 0.7594 0.7507 0.7462 0.7508 0.7502 0.74 0.7444 0.7022 0.7381 0.7331 0.7507 0.7505 0.7371 0.735 0.7421 0.7379 0.7484 0.7505 0.7515 0.7645 0.7413 0.7234 0.7488 0.7448 0.7227 0.7512 0.737 0.7326 0.7545 0.7474 0.7586 0.7405 0.7599 0.7449 0.7458 0.7544 0.7539 0.7573 0.765 
config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 51), 'alpha': (0.05, 0.05), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 10, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.PROB_SRCV: 2>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.CV_GREEDY: 3>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/cvg_cvs/', 'test_mark': '_fmnist', 'comment': ''}

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 51), 'alpha': (0.05, 0.05), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 10, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.PROB_SRCV: 2>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.CV_GREEDY: 3>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/cvg_cvs/', 'test_mark': '_fmnist', 'comment': ''}
0.2796 0.4467 0.5838 0.5707 0.5803 0.6328 0.6522 0.6414 0.6265 0.6002 0.6344 
config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 51), 'alpha': (0.05, 0.05), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 5, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.PROB_SRCV: 2>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.CV_GREEDY: 3>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/cvg_cvs/', 'test_mark': '_fmnist', 'comment': ''}
0.2803 0.3331 0.3661 0.3971 0.37 0.3707 0.3572 0.4226 0.474 0.5283 0.5655 0.524 0.6147 0.5736 0.5408 0.5788 0.5651 0.4623 0.5551 0.5584 0.5525 0.5354 0.6326 0.5799 0.4749 0.6342 0.5778 0.5238 0.6412 0.5786 0.6379 0.6239 0.593 0.5651 0.6025 0.5374 0.6294 0.5216 0.6588 0.6386 0.6445 0.6239 0.5983 0.6498 0.6068 0.5451 0.5425 0.622 0.5929 0.6578 0.6358 0.6464 0.631 0.6628 0.6865 0.6822 0.6451 0.638 0.6573 0.6382 0.7022 0.6205 0.6611 0.6424 0.6389 0.6469 0.691 0.6519 0.711 0.6752 0.5484 0.6622 0.6945 0.6575 0.7062 0.6707 0.6839 0.67 0.6936 0.6763 0.6723 0.6731 0.6519 0.6577 0.6455 0.6966 0.6301 0.6539 0.6201 0.6979 0.5968 0.6845 0.6925 0.6866 0.6525 0.6946 0.6993 0.6808 0.7036 0.689 0.7185 0.6769 0.6322 0.6936 0.7289 0.6932 0.6869 0.6535 0.6929 0.7006 0.6565 0.6675 0.6723 0.725 0.6807 0.7203 0.6956 0.6767 0.7462 0.7137 0.7197 0.6917 0.686 0.5948 0.6192 0.6851 0.7311 0.7027 0.6813 0.6925 0.6928 0.6882 0.723 0.7375 0.6976 0.675 0.6649 0.7172 0.7332 0.728 0.7011 0.7161 0.6642 0.7294 0.7087 0.699 0.7174 0.7186 0.6531 0.7232 0.7111 0.6748 0.7073 0.6848 0.7024 0.7378 0.7386 0.7497 0.7415 0.7145 0.6627 0.6974 0.7408 0.7365 0.6384 0.7216 0.757 0.7177 0.7046 0.7466 0.7192 0.7075 0.6845 0.7336 0.7064 0.716 0.7606 0.7142 0.7165 0.6995 0.6907 0.7305 0.7377 0.7267 0.6761 0.6908 0.7049 0.736 0.7168 0.7525 0.6977 0.7546 0.6865 0.7363 0.7127 0.7471 0.7138 0.7252 0.7346 0.7454 0.7259 0.7101 0.7171 0.7352 0.7393 0.7217 0.7277 0.7305 0.7169 0.687 0.6618 0.7152 0.7173 0.6868 0.738 0.7374 0.7089 0.741 0.6994 0.7382 0.7329 0.7048 0.7165 0.7103 0.7563 0.7601 0.7456 0.7369 0.7334 0.697 0.7097 0.7467 0.7281 0.7336 0.7046 0.7058 0.765 0.7286 0.7477 0.6901 0.7326 0.6968 0.7685 0.7339 0.7307 0.719 0.7518 0.7034 0.7345 0.7554 0.7471 0.7407 0.7073 0.7455 0.7228 0.7546 0.7672 0.7236 0.732 0.7411 0.7401 0.7205 0.7332 0.7031 0.7496 0.7399 0.7261 0.7238 0.7443 0.7423 0.7089 0.7378 0.6661 0.7207 0.7547 0.7431 0.7502 0.7333 0.704 0.7553 0.74 0.7305 0.7235 0.7495 0.7367 0.7477 0.7233 0.7553 0.7231 0.7146 0.7371 0.7007 0.7382 0.7273 0.7218 0.696 0.7538 0.7461 0.761 0.7413 0.7471 0.7544 0.7439 0.7217 0.7227 0.7512 0.7067 0.7396 0.7473 0.726 0.7492 0.7097 0.7379 0.7433 0.7657 0.7361 0.7433 0.7392 0.7553 0.7286 0.7624 0.7624 0.7386 0.7587 0.7486 0.7584 0.7401 0.7385 0.7355 0.7371 0.7162 0.7544 0.7427 0.7428 0.7555 0.7445 0.7454 0.7512 0.7552 0.7215 0.7483 0.7451 0.7607 0.7533 0.7241 0.7409 0.7389 0.7616 0.7677 0.7458 0.7602 0.7371 0.7546 0.7444 0.7655 0.7258 0.7654 0.765 0.7621 0.7454 0.7082 0.7291 0.7507 0.7493 0.7441 0.7457 0.7304 0.7229 0.7401 0.7574 0.7463 0.7491 0.7623 0.7248 0.7482 0.7351 0.69 0.7229 0.7333 0.7486 0.7388 0.7499 0.755 0.7617 0.7536 0.7418 0.7605 0.7573 0.759 0.7371 0.7583 0.7393 0.7506 0.7371 0.7578 0.7606 0.7707 0.719 0.7425 0.7338 0.746 0.7456 0.7055 0.7231 0.75 0.7519 0.7263 0.7464 0.7536 0.7439 0.7488 0.7516 0.7496 0.7177 0.7263 0.7411 0.756 0.7566 0.7493 0.7499 0.744 0.7505 0.7452 0.7598 0.7548 0.7609 0.7337 0.7406 0.7554 0.7557 0.7554 0.7399 0.7571 0.7578 0.7658 0.7207 0.7469 0.7702 0.755 0.7704 0.7556 0.7325 0.7484 0.7219 0.7472 0.7613 0.7673 0.7484 0.7255 0.7602 0.7466 0.758 0.7459 0.7354 0.749 0.748 0.7606 0.7705 0.7683 0.7347 0.7626 0.7196 0.7669 0.7354 0.7577 0.7292 0.7566 0.7426 0.7639 0.7643 0.7417 0.7303 0.7224 0.7393 0.7586 0.7515 0.7401 0.7535 0.7581 0.7474 0.7465 0.7513 0.7381 0.7557 0.7521 0.7372 0.7364 0.7576 0.7159 0.7747 0.7653 0.7425 0.7589 0.7482 0.758 0.7657 0.762 0.7659 0.7679 0.7591 0.7288 0.7621 0.7605 0.7426 0.7427 0.7533 0.7603 0.7668 0.7449 0.7289 0.7486 0.7544 0.7471 0.7608 0.759 0.7433 0.7348 0.7628 0.7375 0.7563 0.7569 0.7549 0.7496 0.7603 0.7585 0.7544 0.7642 0.7792 0.7746 0.7787 0.7331 0.7627 0.75 0.7562 0.7488 0.7565 0.7772 0.7585 0.7558 0.754 0.7358 0.735 0.7502 0.7639 0.755 0.7729 0.7368 0.7493 0.7663 0.7782 0.7772 0.7645 0.7581 0.7488 0.7485 0.7582 0.7633 0.7597 0.7537 0.763 0.7386 0.7675 0.7708 0.7608 0.7579 0.764 0.764 0.773 0.7391 0.7619 0.7575 0.7643 0.7572 0.7519 0.7668 0.769 0.7784 0.754 0.77 0.7818 0.7722 0.753 0.7473 0.762 0.7649 0.7437 0.7748 0.7654 0.7412 0.7522 0.7307 0.7386 0.7614 0.7528 0.7725 0.7621 0.7663 0.7475 0.7552 0.7407 0.7154 0.7696 0.7678 0.7594 0.7404 0.7533 0.7656 0.775 0.7708 0.7688 0.7596 0.7726 0.7729 0.76 0.7574 0.7707 0.7602 0.7679 0.7534 0.7665 0.7762 0.7558 0.7666 0.7423 0.7657 0.7524 0.7602 0.7541 0.7444 0.7573 0.7593 0.7546 0.7687 0.7673 0.7606 0.7408 0.7584 0.7614 0.769 0.771 0.7714 0.7756 0.7775 0.7728 0.7694 0.7553 0.7578 0.7609 0.7559 0.7633 0.7732 0.7632 0.76 0.7609 0.7236 0.7642 0.7534 0.7487 0.7669 0.7497 0.7571 0.7625 0.7429 0.767 0.7765 0.7703 0.7673 0.7305 0.7608 0.7718 0.7687 0.7558 0.7634 0.7837 0.7749 0.7501 0.7511 0.7268 0.7792 0.7352 0.7579 0.7645 0.7685 0.7668 0.7619 0.7536 0.7683 0.7714 0.765 0.7632 0.772 0.775 0.7742 0.7496 0.7573 0.7638 0.7692 0.7516 0.7535 0.7629 0.7552 0.7613 0.7613 0.767 0.7344 0.7697 0.7579 0.7728 0.7629 0.7701 0.771 0.764 0.7639 0.7662 0.7717 0.7582 0.77 0.7595 0.775 0.7701 0.7715 0.769 0.7539 0.7559 0.7562 0.7751 0.7764 0.7671 0.761 0.7591 0.7441 0.7502 0.7603 0.7619 0.7559 0.7649 0.7275 0.7624 0.776 0.7777 0.7736 0.77 0.7791 0.7605 0.7624 0.76 0.773 0.7753 0.7618 0.7454 0.7676 0.7523 0.7603 0.7517 0.7661 0.7649 0.7697 0.7685 0.7763 0.7767 0.7696 0.7666 0.7618 0.7651 0.7707 0.7638 0.7524 0.7622 0.7478 0.755 0.7665 0.7762 0.7515 0.7523 0.7707 0.7717 0.7649 0.7654 0.7767 0.7765 0.7711 0.7757 0.7711 0.7592 0.7398 0.7689 0.7487 0.7741 0.7549 0.7539 0.7402 0.7351 0.7516 0.7337 0.765 0.7652 0.7496 0.7584 0.7569 0.7573 0.7613 0.7533 0.7551 0.747 0.7329 0.7391 0.7666 0.749 0.7598 0.7629 0.7659 0.7624 0.7603 0.7715 0.7661 0.7649 0.7542 0.7413 0.7634 0.776 0.7269 0.7475 0.7626 0.76 0.7676 0.775 0.7672 0.7697 0.7607 0.7633 0.7655 0.7651 0.7633 0.7117 0.7448 0.7618 0.7501 0.761 0.7555 0.756 0.7654 0.7754 0.77 0.7695 0.7764 0.7334 0.763 0.772 0.7677 0.769 0.7592 0.7474 0.7749 0.7668 0.7645 0.77 0.7624 0.7692 0.7638 0.7571 0.775 0.7532 0.7778 0.7761 0.7709 0.7636 0.7717 0.771 0.7513 0.7726 0.774 0.7856 0.7755 0.7632 0.7855 0.7714 0.7291 0.7588 0.7609 0.7338 0.7708 0.7229 0.7557 0.7564 0.767 0.7763 0.7777 0.7849 0.7823 0.7684 0.7743 0.7749 0.7719 0.7772 0.7651 0.7709 0.7767 0.7712 0.7745 0.7462 0.7483 0.7705 0.7762 0.7781 0.7756 0.7622 0.7612 0.7755 0.7468 0.7543 0.7589 0.7662 0.7648 0.7644 0.7703 0.7688 0.7747 0.769 0.7372 0.7518 0.7662 0.7548 0.7661 0.7735 0.7755 0.7762 0.7741 0.7755 0.7776 0.7659 0.7506 0.7586 0.7453 0.7613 0.7759 0.7671 0.7698 0.7727 0.7754 0.7747 0.7631 0.7704 0.7357 0.745 0.74 0.709 0.7615 0.7463 0.7466 0.7757 0.7575 0.7849 0.7504 0.7727 0.7761 0.7703 0.7488 0.7833 0.7677 0.7641 0.768 0.7656 0.7823 0.7732 0.763 0.7649 0.7751 0.7722 0.7735 0.7799 0.7648 0.7553 0.7718 0.771 0.7689 0.7544 0.7686 0.7683 0.7495 0.7478 0.762 0.7725 0.7636 0.7576 0.7351 0.7707 0.7573 0.7749 0.763 0.7676 0.7623 0.7558 0.7294 0.7541 0.7673 0.7673 0.7727 0.7736 0.7786 0.7688 
config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 51), 'alpha': (0.05, 0.05), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 5, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.PROB_SRCV: 2>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.CV_GREEDY: 3>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/cvg_cvs/', 'test_mark': '_fmnist', 'comment': ''}
0.1701 0.262 0.4331 0.3943 0.5232 0.5103 0.5669 0.5157 0.5506 0.5707 0.6141 0.6005 0.5983 0.5661 0.5882 0.6047 0.6559 0.5385 0.6599 0.5764 0.5785 0.6276 0.6683 0.6009 0.6641 0.6674 0.6732 0.6882 0.613 0.5999 0.6836 0.6434 0.6577 0.6849 0.6123 0.6951 0.6616 0.6335 0.6145 0.6549 0.6935 0.6714 0.6373 0.6574 0.7231 0.6197 0.6725 0.6669 0.6472 0.6934 0.6829 0.7037 0.7333 0.7181 0.7407 0.7211 0.7221 0.6928 0.5521 0.7086 0.6624 0.6799 0.5708 0.7083 0.708 0.717 0.6553 0.7157 0.7073 0.706 0.6963 0.6986 0.6872 0.6155 0.7338 0.6676 0.6588 0.717 0.5866 0.6671 0.7358 0.6248 0.7278 0.6418 0.7481 0.7431 0.7483 0.6933 0.7361 0.7294 0.7393 0.7469 0.7342 0.7026 0.5925 0.7077 0.7138 0.657 0.7321 0.7213 0.7386 0.7255 0.6584 0.6946 0.7413 0.7506 0.7311 0.6953 0.7565 0.6984 0.7626 0.7188 0.7619 0.7553 0.7578 0.7216 0.7451 0.7434 0.7592 0.6662 0.6524 0.7295 0.704 0.7365 0.7293 0.7451 0.7572 0.7337 0.744 0.7444 0.7394 0.6995 0.7376 0.704 0.7591 0.7634 0.7586 0.7594 0.7415 0.7442 0.6606 0.6805 0.7267 0.7293 0.7205 0.7622 0.7177 0.7522 0.752 0.6904 0.705 0.7356 0.7041 0.7382 0.7486 0.6724 0.7393 0.7631 0.7638 0.7369 0.7099 0.7182 0.693 0.7018 0.7448 0.7044 0.7467 0.7083 0.7337 0.7121 0.7558 0.749 0.7609 0.7065 0.769 0.6984 0.7404 0.7359 0.7594 0.7674 0.7558 0.7706 0.7555 0.7471 0.7515 0.7379 0.749 0.7078 0.7132 0.7269 0.7192 0.741 0.7149 0.7283 0.7285 0.7323 0.7116 0.7588 0.7609 0.738 0.7428 0.7639 0.7385 0.731 0.7068 0.7082 0.7691 0.7622 0.6896 0.6935 0.7435 0.7414 0.7325 0.7348 0.7707 0.765 0.7673 0.7373 0.7734 0.7594 0.7375 0.7549 0.7686 0.7433 0.7627 0.747 0.7562 0.7691 0.7146 0.7497 0.7512 0.7493 0.7452 0.7021 0.6822 0.7069 0.6844 0.7381 0.7386 0.7256 0.7492 0.758 0.7507 0.7484 0.7591 0.7514 0.7411 0.7466 0.6959 0.7195 0.7358 0.7581 0.7224 0.7652 0.7706 0.7372 0.7133 0.7315 0.7422 0.7183 0.7584 0.6884 0.7385 0.7355 0.6955 0.7614 0.7568 0.736 0.772 0.7303 0.7754 0.7796 0.7695 0.7683 0.7665 0.7636 0.7552 0.773 0.746 0.7681 0.7572 0.7667 0.7539 0.7571 0.7514 0.7385 0.7406 0.7103 0.7778 0.7544 0.7679 0.773 0.7545 0.7658 0.7717 0.7312 0.7596 0.7627 0.7214 0.7569 0.7192 0.7631 0.7633 0.7259 0.7491 0.7708 0.7824 0.7283 0.751 0.7763 0.772 0.7253 0.67 0.7403 0.7636 0.776 0.7722 0.7746 0.7732 0.7787 0.7782 0.7525 0.7809 0.7665 0.721 0.725 0.7839 0.7593 0.6668 0.7529 0.7514 0.7446 0.7762 0.6635 0.7542 0.7453 0.7535 0.7307 0.7325 0.7523 0.7697 0.7576 0.7468 0.7436 0.7252 0.7532 0.7439 0.7306 0.7068 0.7446 0.7483 0.7743 0.7826 0.7677 0.7716 0.7712 0.7141 0.7439 0.7492 0.763 0.7719 0.7592 0.7681 0.6935 0.7564 0.7696 0.7804 0.7355 0.7172 0.7266 0.782 0.7483 0.7287 0.714 0.7626 0.7276 0.7772 0.765 0.7431 0.7421 0.7318 0.7842 0.7157 0.7674 0.7675 0.7616 0.7589 0.7633 0.7457 0.7476 0.7779 0.7668 0.7274 0.7634 0.7368 0.7647 0.7839 0.7709 0.7613 0.749 0.7618 0.7614 0.7776 0.7809 0.7244 0.7257 0.7699 0.7609 0.7767 0.7695 0.782 0.7819 0.7674 0.7517 0.733 0.7627 0.777 0.7492 0.76 0.7703 0.7714 0.7735 0.7793 0.7604 0.76 0.7759 0.7658 0.7837 0.78 0.7655 0.7551 0.7224 0.778 0.7604 0.7761 0.7758 0.7815 0.7787 0.784 0.6891 0.7618 0.7587 0.7701 0.7731 0.7573 0.7733 0.7731 0.7336 0.7541 0.7761 0.7612 0.7644 0.7532 0.7436 0.7519 0.7565 0.7745 0.7711 0.7778 0.7736 0.7678 0.7822 0.7441 0.7603 0.7373 0.7716 0.7708 0.7781 0.7791 0.772 0.7629 0.7799 0.7547 0.7434 0.7339 0.7645 0.7782 0.7642 0.7051 0.7789 0.7751 0.7538 0.7436 0.7476 0.7721 0.7723 0.7765 0.7666 0.6914 0.7433 0.773 0.7683 0.7573 0.777 0.726 0.7783 0.7523 0.7646 0.7855 0.7812 0.7799 0.7666 0.7878 0.7769 0.7318 0.7744 0.7866 0.7717 0.7435 0.7544 0.7415 0.7642 0.7579 0.7848 0.7901 0.7611 0.7708 0.764 0.7497 0.7539 0.7643 0.7737 0.7681 0.7618 0.7829 0.7742 0.7583 0.7764 0.7668 0.7776 0.7534 0.789 0.7821 0.77 0.778 0.7762 0.775 0.7225 0.7285 0.7823 0.7661 0.7759 0.7605 0.7594 0.7874 0.7855 0.7668 0.7535 0.7555 0.777 0.7755 0.773 0.7815 0.782 0.7772 0.785 0.7761 0.7724 0.7777 0.7251 0.7596 0.7515 0.7477 0.7645 0.7776 0.7684 0.7418 0.784 0.7778 0.7257 0.7565 0.7582 0.7804 0.7742 0.7849 0.7865 0.7571 0.778 0.7373 0.7709 0.7771 0.7762 0.7344 0.7768 0.7837 0.7381 0.7697 0.7551 0.7832 0.7002 0.7782 0.777 0.7267 0.7789 0.7745 0.7811 0.751 0.7821 0.7818 0.7682 0.7817 0.7884 0.7701 0.7566 0.7604 0.776 0.7799 0.746 0.7732 0.7668 0.7718 0.7826 0.7726 0.776 0.776 0.7682 0.7674 0.7722 0.7798 0.783 0.7724 0.7667 0.7723 0.7778 0.7755 0.7714 0.7601 0.7341 0.784 0.7684 0.7869 0.7817 0.761 0.7695 0.7535 0.7675 0.7759 0.7798 0.7644 0.7062 0.7791 0.7845 0.7787 0.7848 0.7632 0.7812 0.7683 0.7811 0.7747 0.772 0.7865 0.7799 0.7478 0.7696 0.788 0.768 0.7793 0.7573 0.7739 0.7828 0.7807 0.7055 0.7717 0.7704 0.7724 0.7786 0.7717 0.7681 0.7851 0.774 0.7536 0.7649 0.7702 0.7797 0.7756 0.7719 0.7839 0.7785 0.7744 0.758 0.7721 0.7843 0.7819 0.7599 0.7849 0.7725 0.7788 0.7819 0.7415 0.721 0.7885 0.7752 0.7661 0.7778 0.7722 0.7747 0.7832 0.7862 0.7848 0.7761 0.7677 0.7713 0.7726 0.7735 0.7833 0.7839 0.6883 0.7406 0.7324 0.7768 0.7814 0.7729 0.7752 0.7822 0.777 0.7853 0.778 0.7355 0.7508 0.7606 0.7769 0.7436 0.7731 0.7741 0.7863 0.7842 0.7702 0.773 0.7737 0.7804 0.7829 0.7594 0.7838 0.7832 0.776 0.7809 0.782 0.7734 0.7725 0.7754 0.7786 0.7845 0.771 0.7821 0.7779 0.7825 0.7855 0.7711 0.777 0.7533 0.7832 0.763 0.7825 0.7835 0.7735 0.7817 0.781 0.7796 0.7704 0.773 0.7791 0.7863 0.7806 0.7607 0.7639 0.7849 0.7131 0.7584 0.7856 0.7738 0.7577 0.7804 0.7912 0.7769 0.7829 0.7843 0.7826 0.786 0.7829 0.7553 0.7772 0.7741 0.7695 0.7725 0.7868 0.7841 0.7834 0.7804 0.7838 0.7613 0.7848 0.7653 0.783 0.7475 0.7662 0.7712 0.7725 0.7837 0.7782 0.787 0.7783 0.7712 0.7757 0.7576 0.7848 0.772 0.772 0.7773 0.7829 0.7862 0.7881 0.7696 0.7858 0.7721 0.7614 0.75 0.785 0.7725 0.755 0.7703 0.7859 0.74 0.7824 0.7741 0.7765 0.7749 0.7749 0.7691 0.7726 0.7748 0.7757 0.7042 0.7758 0.7706 0.77 0.7661 0.7824 0.775 0.7568 0.7646 0.7583 0.7703 0.7743 0.7615 0.7755 0.7731 0.7888 0.7811 0.789 0.7823 0.7747 0.7693 0.7846 0.758 0.782 0.7805 0.7779 0.7851 0.7889 0.7814 0.761 0.7795 0.7643 0.7828 0.7524 0.7727 0.7763 0.7785 0.7874 0.7224 0.7754 0.7756 0.7934 0.7736 0.7691 0.7849 0.7886 0.7854 0.7886 0.7788 0.7806 0.6982 0.7671 0.7666 0.764 0.7659 0.7836 0.7822 0.772 0.7721 0.7732 0.7834 0.782 0.7396 0.7869 0.773 0.7861 0.7855 0.7792 0.7763 0.7849 0.7874 0.7869 0.7881 0.7735 0.7842 0.7904 0.789 0.7851 0.7182 0.7832 0.7904 0.784 0.7445 0.7679 0.7344 0.7691 0.7663 0.7826 0.7123 0.7791 0.7764 0.7813 0.7896 0.7805 0.7533 0.7862 0.7736 0.7721 0.7731 0.7596 0.7836 0.7909 0.773 0.7734 0.7845 0.786 0.7844 0.7646 0.7748 0.7678 0.7645 0.7603 0.7612 0.7712 0.7751 0.7841 0.7664 0.7858 0.7608 0.7693 0.7746 0.7887 0.7866 0.7771 0.7808 0.7793 0.7363 0.7811 0.7748 0.7708 0.7844 0.7817 0.7817 0.7853 0.7874 0.7797 0.7797 0.7715 0.7733 0.7838 0.7211 0.7683 0.7792 0.7796 0.7875 0.7646 0.7752 0.777 0.7851 0.7024 0.759 0.7785 0.7814 0.7824 0.7845 0.7908 0.7839 0.7875 0.7788 0.7752 0.7771 0.7612 0.7634 0.7775 0.7897 0.7781 0.7842 0.782 0.7887 
config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 51), 'alpha': (0.05, 0.05), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 5, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.PROB_SRCV: 2>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.CV_GREEDY: 3>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/cvg_cvs/', 'test_mark': '_fmnist', 'comment': ''}
0.269 0.3804 0.4425 0.4539 0.4174 0.3805 0.5076 0.4304 0.5555 0.5472 0.5689 0.5955 0.5872 0.5955 0.5709 0.553 0.6286 0.6629 0.6143 0.6875 0.6417 0.6242 0.6607 0.6403 0.657 0.6792 0.6698 0.6738 0.6607 0.6999 0.6104 0.644 0.6622 0.6339 0.6427 0.6556 0.6494 0.6744 0.6739 0.7055 0.6691 0.6952 0.6623 0.6805 0.7195 0.7252 0.6971 0.6705 0.7333 0.6546 0.6861 0.7221 0.7079 0.7068 0.7136 0.7013 0.6324 0.6857 0.6821 0.6561 0.6859 0.6831 0.7043 0.6787 0.6513 0.6702 0.6513 0.7079 0.7246 0.6579 0.6932 0.6748 0.6828 0.6767 0.6742 0.7189 0.686 0.6929 0.7066 0.7084 0.7119 0.7164 0.6877 0.7066 0.7131 0.7003 0.6805 0.7148 0.693 0.6936 0.7488 0.7296 0.6438 0.714 0.6904 0.7078 0.6566 0.7091 0.7231 0.6514 0.7086 0.7004 0.7228 0.7181 0.7266 0.7046 0.6884 0.7048 0.7093 0.6882 0.7233 0.7412 0.7553 0.7179 0.7259 0.7319 0.7341 0.742 0.6826 0.7019 0.6467 0.6698 0.7503 0.6937 0.7198 0.673 0.6978 0.7367 0.6876 0.6999 0.7237 0.7119 0.7335 0.709 0.7056 0.7037 0.7427 0.76 0.7186 0.6919 0.6871 0.6936 0.7329 0.7531 0.7066 0.6741 0.7482 0.7174 0.7285 0.6831 0.7428 0.7651 0.6887 0.7651 0.7015 0.7462 0.7386 0.7545 0.7182 0.7237 0.7577 0.7229 0.7366 0.7493 0.7558 0.7156 0.6829 0.7063 0.7186 0.7503 0.7106 0.6746 0.7065 0.7654 0.7137 0.7411 0.731 0.7686 0.7237 0.7065 0.7453 0.7215 0.7224 0.7347 0.7515 0.6567 0.7232 0.6888 0.7342 0.7628 0.7578 0.7692 0.7628 0.7462 0.7568 0.7692 0.7378 0.7288 0.7381 0.7379 0.708 0.7221 0.7443 0.6951 0.7221 0.7592 0.7187 0.7385 0.7547 0.758 0.7619 0.7679 0.7504 0.7525 0.7571 0.6966 0.6839 0.738 0.7104 0.6733 0.7206 0.7311 0.7353 0.7285 0.7497 0.7665 0.7378 0.733 0.7168 0.7651 0.7258 0.7485 0.7233 0.7566 0.7228 0.7162 0.7381 0.7342 0.7326 0.7235 0.7426 0.7136 0.7614 0.7186 0.7384 0.7552 0.7397 0.7292 0.7644 0.7457 0.7308 0.7459 0.7378 0.7367 0.7644 0.7715 0.7456 0.7692 0.7646 0.7319 0.7481 0.7636 0.7258 0.7693 0.7462 0.7368 0.7459 0.7638 0.735 0.7272 0.7482 0.7589 0.7473 0.7408 0.7699 0.7561 0.704 0.746 0.7583 0.6965 0.7218 0.7622 0.7522 0.7385 0.706 0.7481 0.7251 0.7653 0.7547 0.743 0.7555 0.7462 0.7572 0.743 0.7323 0.7323 0.7607 0.7535 0.7393 0.7473 0.768 0.7379 0.7498 0.7214 0.6934 0.7264 0.7562 0.7521 0.7624 0.7494 0.7527 0.7301 0.7587 0.6705 0.7524 0.7452 0.7402 0.7274 0.7587 0.7438 0.7277 0.7262 0.6549 0.7528 0.7368 0.75 0.7515 0.7343 0.7477 0.7517 0.6841 0.7296 0.7409 0.7504 0.731 0.7441 0.7553 0.7581 0.724 0.7449 0.6877 0.7562 0.7483 0.7343 0.7438 0.7379 0.7674 0.7564 0.7584 0.7636 0.7248 0.7359 0.7736 0.7516 0.7433 0.7788 0.7623 0.7667 0.7178 0.706 0.6717 0.7721 0.768 0.7807 0.7749 0.7457 0.7528 0.7558 0.7594 0.7557 0.7431 0.7341 0.7616 0.7449 0.7594 0.7587 0.7612 0.7347 0.738 0.7511 0.7696 0.7359 0.752 0.748 0.6515 0.7653 0.7596 0.757 0.7531 0.7523 0.7797 0.7637 0.7681 0.7479 0.6935 0.7447 0.7545 0.7637 0.7827 0.7406 0.7645 0.7546 0.7711 0.7664 0.7649 0.7521 0.769 0.7672 0.7666 0.7437 0.7633 0.7471 0.752 0.7483 0.7532 0.7244 0.6841 0.7578 0.751 0.758 0.7453 0.7661 0.7687 0.7828 0.7796 0.7682 0.7621 0.7729 0.7637 0.768 0.7426 0.7515 0.6488 0.7608 0.7731 0.7608 0.7388 0.7411 0.7498 0.756 0.6349 0.7361 0.722 0.7562 0.7551 0.7781 0.7645 0.7552 0.7397 0.7649 0.7755 0.7719 0.7616 0.7398 0.7638 0.684 0.7676 0.7774 0.7648 0.7428 0.6929 0.7536 0.718 0.7754 0.754 0.7726 0.7501 0.772 0.7632 0.7524 0.7541 0.757 0.7616 0.7554 0.7623 0.7753 0.7537 0.695 0.7602 0.7725 0.7512 0.746 0.7675 0.7648 0.7624 0.7816 0.7664 0.7684 0.7522 0.7636 0.7482 0.7427 0.7402 0.7634 0.755 0.7612 0.7483 0.7192 0.751 0.7367 0.7663 0.7731 0.7512 0.7657 0.7779 0.7688 0.7424 0.724 0.7603 0.7632 0.7503 0.704 0.7698 0.7794 0.7736 0.7607 0.7775 0.711 0.7703 0.7617 0.7512 0.7582 0.762 0.7778 0.7527 0.7725 0.7604 0.7307 0.7777 0.7449 0.7159 0.7315 0.7727 0.7755 0.7483 0.7737 0.7738 0.7518 0.7594 0.7539 0.7706 0.7448 0.7739 0.7534 0.7717 0.7375 0.7683 0.751 0.7586 0.7603 0.6751 0.7555 0.7731 0.7684 0.7784 0.7711 0.7268 0.7733 0.7584 0.7641 0.7444 0.7628 0.7653 0.7239 0.753 0.7703 0.7681 0.7745 0.7641 0.7508 0.7627 0.7752 0.768 0.7698 0.7794 0.7445 0.7658 0.7622 0.7526 0.7616 0.7431 0.7517 0.7361 0.7469 0.736 0.7623 0.7673 0.7709 0.6247 0.7697 0.7671 0.7777 0.7813 0.722 0.7693 0.7729 0.7561 0.7718 0.7363 0.7689 0.7743 0.7442 0.7505 0.7561 0.7448 0.7559 0.7266 0.7651 0.7608 0.7528 0.7665 0.7695 0.7558 0.7701 0.7714 0.7512 0.7853 0.7598 0.7835 0.7665 0.7617 0.7665 0.7528 0.7789 0.7712 0.7717 0.7585 0.7694 0.7725 0.7548 0.7339 0.6974 0.7684 0.7739 0.7679 0.7599 0.7573 0.7518 0.7365 0.7492 0.7744 0.7789 0.7708 0.7695 0.7776 0.7587 0.7287 0.7458 0.7781 0.7794 0.772 0.7718 0.7731 0.757 0.755 0.7681 0.764 0.754 0.7814 0.7358 0.7525 0.7503 0.7475 0.7422 0.7633 0.7483 0.7704 0.7712 0.7742 0.7749 0.7707 0.7715 0.7412 0.7632 0.773 0.7639 0.7621 0.7487 0.7646 0.7598 0.741 0.7566 0.7556 0.7698 0.7734 0.7523 0.7665 0.7437 0.757 0.763 0.75 0.7481 0.7285 0.7538 0.7682 0.7682 0.7628 0.7727 0.7489 0.7681 0.784 0.7682 0.7691 0.736 0.6876 0.7621 0.7745 0.7653 0.7482 0.7466 0.7625 0.76 0.7576 0.7609 0.7667 0.7148 0.7473 0.7756 0.7602 0.7806 0.7724 0.7244 0.736 
config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 51), 'alpha': (0.05, 0.05), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 5, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.PROB_SRCV: 2>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.CV_GREEDY: 3>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/cvg_cvs/', 'test_mark': '_fmnist', 'comment': ''}
0.3332 0.4103 0.4418 0.5094 0.6498 0.6312 0.5557 0.6439 0.6474 0.6663 0.6587 0.7017 0.5754 0.7202 0.6293 0.6387 0.7204 0.7171 0.619 0.7324 0.6812 0.721 0.6424 0.7135 0.7314 0.7066 0.6697 0.7213 0.7473 0.7364 0.731 0.7494 0.7397 0.7546 0.6677 0.6791 0.6261 0.7514 0.7487 0.759 0.7261 0.7408 0.7497 0.7337 0.7432 0.7142 0.7064 0.722 0.7489 0.7599 0.7619 0.7703 0.7458 0.7523 0.7296 0.7618 0.7421 0.7461 0.7577 0.7534 0.7627 0.7716 0.7573 0.7421 0.7176 0.7609 0.7661 0.781 0.7311 0.7723 0.7643 0.7378 0.7474 0.7509 0.7528 0.7619 0.7673 0.7611 0.7786 0.7674 0.7689 0.762 0.7342 0.7328 0.7579 0.7767 0.7644 0.7838 0.7705 0.7679 0.7656 0.7733 0.7774 0.7497 0.7875 0.767 0.7566 0.7511 0.7619 0.7835 0.7671 0.7578 0.7624 0.7657 0.7765 0.7094 0.7823 0.7691 0.7719 0.7822 0.7599 0.7559 0.7617 0.7851 0.7513 0.7728 0.7122 0.7684 0.7794 0.7741 0.7685 0.7521 0.7772 0.7839 0.7493 0.7852 0.791 0.7759 0.7692 0.7499 0.79 0.7286 0.7789 0.7522 0.7403 0.7871 0.771 0.765 0.7908 0.7729 0.7744 0.7757 0.7909 0.7685 0.7836 0.7796 0.7776 0.7537 0.7702 0.7819 0.7502 0.7774 0.7608 0.7934 0.7347 0.7346 0.7677 0.7837 0.7764 0.7904 0.7812 0.7872 0.7737 0.7707 0.7855 0.7483 0.7791 0.787 0.7917 0.7761 0.7813 0.7629 0.7788 0.7801 0.7852 0.7729 0.7841 0.7701 0.7692 0.7708 0.7844 0.7947 0.7623 0.794 0.785 0.7624 0.7807 0.7793 0.7896 0.7576 0.7895 0.7927 0.7944 0.78 0.7836 0.7861 0.7911 0.7803 0.7453 0.7957 0.7865 0.7884 0.7747 0.7834 0.7517 0.7756 0.7955 0.7866 0.7503 0.7836 0.7725 0.7177 0.7595 0.7669 0.7929 0.7942 0.7647 0.7864 0.7903 0.7919 0.7892 0.794 0.7829 0.781 0.787 0.7931 0.7807 0.7866 0.7829 0.7787 0.7818 0.7776 0.7339 0.7969 0.7882 0.7803 0.7771 0.7984 0.7826 0.7514 0.7927 0.7629 0.7747 0.7876 0.7809 0.7913 0.7854 0.7855 0.7907 0.7837 0.7808 0.7887 0.772 0.7901 0.7925 0.7811 0.7991 0.7757 0.7825 0.7977 0.7665 0.798 0.7922 0.7835 0.8006 0.7949 0.7888 0.797 0.7739 0.7822 0.7928 0.7935 0.7915 0.7975 0.7907 0.7928 0.753 0.7774 0.781 0.772 0.7839 0.7979 0.7744 0.7965 0.7835 0.7955 0.801 0.7978 0.7871 0.791 0.7856 0.7795 0.7814 0.7936 0.7985 0.7964 0.7984 0.7379 0.7768 0.7962 0.7959 0.7974 0.7687 0.7877 0.7752 0.8002 0.7813 0.7801 0.7937 0.7892 0.7708 0.7869 0.7815 0.7977 0.795 0.7994 0.784 0.7848 0.7981 0.7954 0.7687 0.777 0.7835 0.7995 0.7789 0.7926 0.7912 0.7947 0.744 0.7986 0.7886 0.7532 0.7763 0.7952 0.7792 0.7974 0.7988 0.7655 0.7716 0.7786 0.7974 0.798 0.7943 0.7943 0.7789 0.7957 
config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 51), 'alpha': (0.05, 0.05), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 5, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.PROB_SRCV: 2>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.CV_GREEDY: 3>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/cvg_cvs/', 'test_mark': '_fmnist', 'comment': ''}
0.1499 0.2946 0.3997 0.337 0.438 0.4809 0.5222 0.451 0.4773 0.5164 0.4585 0.5092 0.5362 0.5922 0.6432 0.5306 0.6266 0.6578 0.6608 0.6443 0.5239 0.6559 0.6599 0.6525 0.654 0.6081 0.637 0.652 0.6622 0.6357 0.6846 0.7119 0.711 0.6747 0.6482 0.6858 0.6863 0.6762 0.7092 0.6629 0.7237 0.7017 0.693 0.6533 0.6803 0.7034 0.7096 0.6848 0.6355 0.6654 0.67 0.7092 0.6988 0.6562 0.663 0.6903 0.6974 0.7454 0.6998 0.7019 0.7079 0.6875 0.7252 0.733 0.6731 0.7224 0.6798 0.722 0.7219 0.6921 0.7514 0.6956 0.694 0.7078 0.6112 0.7278 0.6846 0.6904 0.733 0.7035 0.6563 0.6847 0.7158 0.6793 0.7378 0.7405 0.738 0.7341 0.7392 0.6866 0.7171 0.6841 0.7382 0.7485 0.7033 0.7129 0.744 0.7399 0.6427 0.7439 0.7093 0.7433 0.6792 0.6908 0.7698 0.7542 0.7496 0.7136 0.7173 0.6943 0.6852 0.7364 0.732 0.7218 0.6967 0.7179 0.7364 0.729 0.7075 0.696 0.7003 0.7542 0.7349 0.688 0.7345 0.726 0.7172 0.7022 0.7521 0.6953 0.7481 0.6956 0.7562 0.7071 0.7354 0.7286 0.6959 0.7255 0.6663 0.6753 0.7229 0.7295 0.7151 0.7509 0.7665 0.7033 0.7176 0.7185 0.7487 0.7078 0.7575 0.7093 0.6502 0.713 0.7406 0.7176 0.7359 0.7727 0.6794 0.7584 0.7263 0.7325 0.7404 0.7146 0.7203 0.7436 0.7285 0.7507 0.6993 0.659 0.7448 0.7555 0.7141 0.7659 0.7538 0.7607 0.7383 0.72 0.7278 0.7538 0.7369 0.7362 0.7322 0.7209 0.7486 0.7254 0.7207 0.732 0.7166 0.7135 0.7366 0.6863 0.7385 0.7328 0.6999 0.7446 0.7441 0.7499 0.6884 0.7516 0.7309 0.7281 0.7634 0.7308 0.7373 0.7305 0.7573 0.7486 0.7481 0.7629 0.7517 0.735 0.7358 0.7312 0.7306 0.7473 0.7423 0.7572 0.7563 0.7304 0.7258 0.6812 0.7205 0.7469 0.7465 0.7055 0.7593 0.682 0.6783 0.7659 0.7102 0.7566 0.7247 0.7008 0.7545 0.717 0.7355 0.7423 0.7246 0.724 0.7278 0.7495 0.6965 0.7345 0.7247 0.7485 0.7241 0.7607 0.7571 0.7243 0.715 0.6928 0.7337 0.719 0.7016 0.7696 0.7467 0.7199 0.7631 0.7705 0.7571 0.7222 0.7601 0.749 0.7653 0.7471 0.7236 0.7246 0.7545 0.7203 0.7503 0.7439 0.7366 0.7298 0.7371 0.7119 0.7542 0.7254 0.7396 0.7292 0.7149 0.7573 0.7174 0.7571 0.7301 0.7335 0.761 0.7467 0.7803 0.7578 0.7568 0.72 0.7637 0.764 0.7561 0.7413 0.7617 0.7351 0.7589 0.7588 0.7562 0.7619 0.7394 0.7455 0.7477 0.7757 0.7274 0.7527 0.7551 0.7363 0.7317 0.7559 0.7281 0.7613 0.751 0.7633 0.7691 0.7463 0.7196 0.7435 0.7464 0.7182 0.7606 0.7659 0.7342 0.7369 0.7615 0.7677 0.723 0.7497 0.7353 0.7221 0.747 0.7377 0.7734 0.7193 0.7672 0.7607 0.7298 0.7325 0.7451 0.7412 0.7657 0.7406 0.7557 0.7434 0.749 0.7653 0.7698 0.7425 0.7243 0.7482 0.7677 0.7672 0.7528 0.766 0.7147 0.7425 0.7399 0.75 0.7648 0.7611 0.6991 0.7657 0.7312 0.7209 0.7561 0.751 0.7296 0.7386 0.78 0.7563 0.7585 0.7661 0.7563 0.7351 0.7364 0.7414 0.7514 0.7736 0.7557 0.7424 0.7617 0.7755 0.7585 0.7388 0.7272 0.7315 0.7381 0.7455 0.7547 0.7661 0.7564 0.7286 0.7076 0.7392 0.7497 0.747 0.7529 0.7608 0.7532 0.7459 0.766 0.7343 0.7475 0.7424 0.7342 0.7708 0.7553 0.7592 0.7544 0.7528 0.7495 0.746 0.7556 0.7569 0.7557 0.7649 0.7248 0.7302 0.7416 0.733 0.7525 0.7467 0.77 0.7211 0.7706 0.7578 0.7434 0.7638 0.7487 0.7652 0.7666 0.7764 0.7578 0.7249 0.7641 0.7587 0.7402 0.7697 0.7626 0.7725 0.766 0.7536 0.7231 0.7634 0.7735 0.7744 0.7724 0.7725 0.7523 0.7738 0.7416 0.7688 0.7725 0.7499 0.7472 0.7563 0.7466 0.7614 0.7434 0.7388 0.7583 0.7642 0.778 0.774 0.7144 0.7089 0.7512 0.7765 0.7495 0.7452 0.7417 0.7544 0.7294 0.7629 0.7718 0.7658 0.756 0.7634 0.7564 0.7598 0.746 0.7269 0.7713 0.7465 0.7376 0.7641 0.7558 0.7653 0.7668 0.7693 0.7244 0.7588 0.7561 0.7563 0.7751 0.741 0.7137 0.7392 0.7175 0.7528 0.7473 0.7364 0.7575 0.7696 0.7701 0.7789 0.7635 0.7449 0.751 0.7502 0.7658 0.7251 0.76 0.7652 0.73 0.7815 0.7588 0.7315 0.7146 0.7572 0.7711 0.7735 0.7684 0.7556 0.7602 0.7664 0.7441 0.7489 0.7577 0.755 0.7711 0.77 0.7682 0.7834 0.763 0.7728 0.7535 0.7723 0.7727 0.7628 0.7709 0.7804 0.7705 0.7614 0.7511 0.7575 0.7683 0.7733 0.7468 0.7754 0.768 0.736 0.7576 0.7445 0.7636 0.7543 0.7726 0.7725 0.7505 0.7748 0.7681 0.7767 0.7727 0.7378 0.7614 0.7531 0.7705 0.7423 0.7546 0.7718 0.7599 0.7778 0.7579 0.7436 0.7507 0.759 0.7715 0.7274 0.7749 0.7798 0.7481 0.7589 0.7525 0.7654 0.7759 0.7733 0.7415 0.7481 0.7521 0.7604 0.7567 0.7586 0.7593 0.7742 0.7542 0.7397 0.7648 0.7785 0.7593 0.7417 0.7774 0.7554 0.7602 0.7719 0.7535 0.7615 0.7558 0.7676 0.7763 0.7437 0.7597 0.7623 0.7735 0.7581 0.7521 0.7577 0.7809 0.7421 0.7731 0.7708 0.7601 0.7456 0.7318 0.7649 0.7422 0.7628 0.755 0.7647 0.7661 0.7659 0.7364 0.7531 0.7439 0.7694 0.7749 0.7539 0.7798 0.7745 0.7729 0.7793 0.7521 0.7434 0.7818 0.782 0.7609 0.7835 0.7795 0.7305 0.7719 0.7119 0.7349 0.7567 0.7543 0.7645 0.7491 0.7104 0.7661 0.761 0.7661 0.7808 0.7685 0.7341 0.7645 0.7664 0.7702 0.7802 0.7789 0.7435 0.7727 0.7685 0.7744 0.769 0.7214 0.7429 0.7758 0.7676 0.7559 0.7783 0.7804 0.7615 0.7832 0.7408 0.7628 0.7667 0.7479 0.7656 0.7758 0.785 0.7647 0.7794 0.7436 0.7776 0.7512 0.763 0.771 0.7679 0.7421 0.7699 0.7455 0.747 0.7753 0.756 0.7643 0.7757 0.7489 0.7593 0.7786 0.7749 0.7632 0.782 0.7495 0.7698 0.7563 0.751 0.7716 0.7824 0.7771 0.7734 0.7752 0.7893 0.771 0.7718 0.7683 0.769 0.7641 0.745 0.7545 0.7493 0.7823 0.7725 0.7726 0.7592 0.7385 0.7701 0.752 0.7615 0.7704 0.7721 0.7605 0.775 0.7787 0.7624 0.7394 0.7721 0.7627 0.7776 0.7593 0.7401 0.7686 0.7759 0.7467 0.7644 0.7727 0.7542 0.7363 0.7663 0.75 0.7779 0.7771 0.7489 0.7618 0.7569 0.7483 0.7771 0.7799 0.7547 0.7688 0.7616 0.7815 0.7703 0.7538 0.7581 0.7722 0.7642 0.7678 0.7617 0.7584 0.7677 0.7622 0.7736 0.7223 0.764 0.7794 0.764 0.7749 0.7605 0.7804 0.7788 0.7736 0.7501 0.7626 0.7672 0.7578 0.7653 0.7465 0.771 0.7574 0.7615 0.7684 0.7593 0.765 0.7666 0.7768 0.7653 0.7674 0.7426 0.7734 0.7589 0.7695 0.7784 0.7618 0.7708 0.7539 0.7763 0.7638 0.7779 0.7396 0.7709 0.7697 0.7679 0.7496 0.7685 0.7672 0.7656 0.7603 0.7472 0.7726 0.7635 0.7651 0.7732 0.7576 0.7626 0.7663 0.7548 0.7643 0.7771 0.7638 0.7636 0.7696 0.7757 0.7563 0.7716 0.7568 0.762 0.7571 0.7738 0.7713 0.7775 0.7538 0.7562 0.7785 0.7656 0.7701 0.7615 0.7667 0.75 0.7607 0.7651 0.768 0.7722 0.7706 0.7763 0.7692 0.7216 0.7671 0.7665 0.7788 0.7664 0.7486 0.7702 0.768 0.7592 0.7815 0.7205 0.7555 0.7706 0.7629 0.7755 0.7743 0.7706 0.7694 0.7671 0.7624 0.7501 0.7621 0.7716 0.7743 0.7728 0.7806 0.7669 0.7656 0.7626 0.7636 0.7662 0.7628 0.7522 0.7732 0.7744 0.7631 0.7703 0.762 0.7667 0.7727 0.7745 0.7695 0.7794 0.7785 0.7725 0.7437 0.7744 0.752 0.7629 0.7524 0.7479 0.7758 0.7547 0.7746 0.7769 0.7757 0.7602 0.7668 0.7707 0.7787 0.7707 0.7681 0.7685 0.7659 0.7716 0.7578 0.7613 0.7634 0.7588 0.7653 0.7686 0.7711 0.774 0.7653 0.7708 0.7706 0.7577 0.7697 0.7563 0.7656 0.7711 0.7624 0.7684 0.7608 0.7658 0.7731 0.7729 0.767 0.7796 0.7493 0.758 0.7644 0.7659 0.758 0.7804 0.7786 0.7812 0.7701 0.7803 0.7732 0.7731 0.7635 0.7634 0.7707 0.7596 0.785 0.7732 0.7804 0.7648 0.7702 0.7627 0.7716 0.7627 0.7716 0.764 0.7761 0.764 0.7702 0.7743 0.7715 0.7556 0.7619 0.7697 0.7572 0.772 0.7834 0.7725 0.7713 0.7742 0.7781 0.7769 0.7736 0.7532 0.7481 0.769 
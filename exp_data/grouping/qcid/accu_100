
config:{'task_name': <TaskName.CIFAR: 1>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 1, 'lr_interval': 1000, 'lr': 0.01, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.QCID: 7>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/qcid/', 'test_mark': '_100', 'comment': ''}

config:{'task_name': <TaskName.CIFAR: 1>, 'server_num': 2, 'client_num': 200, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 1, 'lr_interval': 1000, 'lr': 0.01, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.QCID: 7>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/qcid/', 'test_mark': '_100', 'comment': ''}

config:{'task_name': <TaskName.CIFAR: 1>, 'server_num': 3, 'client_num': 300, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 1, 'lr_interval': 1000, 'lr': 0.01, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.QCID: 7>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/qcid/', 'test_mark': '_100', 'comment': ''}
0.1 0.1029 0.1 0.1763 0.1 0.2358 0.1798 0.1923 0.2621 0.2023 0.1597 0.2668 0.3224 0.3785 
config:{'task_name': <TaskName.CIFAR: 1>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 1, 'lr_interval': 1000, 'lr': 0.01, 'batch_size': 10, 'device': 'cuda:0', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.QCID: 7>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/qcid/', 'test_mark': '_100', 'comment': ''}

config:{'task_name': <TaskName.CIFAR: 1>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 1, 'lr_interval': 1000, 'lr': 0.01, 'batch_size': 10, 'device': 'cuda:0', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.QCID: 7>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/qcid/', 'test_mark': '_100', 'comment': ''}

config:{'task_name': <TaskName.CIFAR: 1>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 1, 'lr_interval': 1000, 'lr': 0.01, 'batch_size': 10, 'device': 'cuda:0', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.QCID: 7>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/qcid/', 'test_mark': '_100', 'comment': ''}

config:{'task_name': <TaskName.CIFAR: 1>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 1, 'lr_interval': 1000, 'lr': 0.01, 'batch_size': 10, 'device': 'cuda:0', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.QCID: 7>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/qcid/', 'test_mark': '_100', 'comment': ''}
0.1 0.1253 0.2782 0.2667 0.2988 0.3109 0.3066 0.3221 0.2892 0.3492 0.2766 0.4129 0.4144 0.3606 0.394 0.4637 0.3955 0.4534 0.4538 0.4627 0.4681 0.468 0.5556 0.4526 0.5108 0.4821 0.5038 0.447 0.4681 0.4746 0.5386 0.4483 0.4772 0.5053 0.5411 0.4449 0.4467 0.4795 0.5226 0.5589 0.5066 0.5471 0.5287 0.5044 0.5891 0.5986 0.5121 0.5635 0.5687 0.568 0.6064 0.5518 0.6389 0.6126 0.6271 0.5876 0.5745 0.6544 0.56 0.6225 0.5302 0.5846 0.5986 0.5903 0.5914 0.5876 0.6292 0.6396 0.6282 0.5945 0.5908 0.5816 0.5995 0.6833 0.6289 0.5461 0.5996 0.6391 0.6733 0.63 0.5986 0.5671 0.6572 0.678 0.6563 0.6306 0.6773 0.6796 0.6571 0.5508 0.5463 0.6418 0.6723 0.6723 0.6733 0.6261 0.6579 0.6804 0.6455 0.6487 0.6967 0.6388 0.6808 0.6025 0.6786 0.6435 0.6484 0.6789 0.6527 0.6882 0.6456 0.6702 0.667 0.6824 0.709 0.6761 0.6356 0.6204 0.6516 0.7033 0.6982 0.7009 0.7018 0.6756 0.6686 0.6774 0.688 0.7211 0.7049 0.7159 0.6712 0.6422 0.6521 0.6537 0.6731 0.6586 0.7059 0.6989 0.7157 0.7083 0.7118 0.7112 0.69 0.6763 0.641 0.6482 0.6977 0.6416 0.6943 0.6954 0.7151 0.7005 0.6774 0.6865 0.722 0.6942 0.6957 0.7143 0.6768 0.7158 0.6968 0.6557 0.6647 0.6615 0.6974 0.6915 0.7166 0.7245 0.7155 0.6603 0.7023 0.7051 0.6746 0.7376 0.7152 0.698 0.7309 0.7253 0.7279 0.7196 0.7142 0.7259 0.7225 0.7406 0.6943 0.7316 0.6752 0.7092 0.6763 0.7321 0.6717 0.7199 0.7317 0.7031 0.7337 0.6991 0.688 0.6432 0.7342 0.6666 0.7072 0.6734 0.7121 0.7221 0.7466 0.743 0.6577 0.689 0.7354 0.6941 0.729 0.6273 0.7012 0.7115 0.6671 0.705 0.6925 0.7364 0.7414 0.7335 0.6671 0.6898 0.7047 0.7509 0.752 0.6999 0.6569 0.7327 0.6958 0.7347 0.7226 0.7126 0.715 0.7324 0.7264 0.7374 0.7453 0.7155 0.7288 0.724 0.6646 0.7011 0.7256 0.7134 0.6417 0.7049 0.7368 0.7077 0.7138 0.7171 0.7459 0.6995 0.7169 0.7088 0.7277 0.7098 0.7131 0.7429 0.7298 0.7102 0.7135 0.733 0.6517 0.7156 0.7441 0.732 0.7355 0.7234 0.7155 0.7362 0.7538 0.7498 0.7389 0.7089 0.7123 0.7266 0.6836 0.7498 0.7469 0.7279 0.7034 0.7229 0.7214 0.7205 0.7195 0.7364 0.7323 0.744 0.7296 0.7156 0.7327 0.7156 0.7372 0.7428 0.7199 0.7386 0.7509 0.7189 0.7545 0.704 0.739 0.7317 0.7403 0.7186 0.7496 0.7386 0.6938 0.7404 0.6952 0.7386 0.7341 0.7339 0.7685 0.7184 0.6693 0.7071 0.7392 0.7062 0.7547 0.7226 0.7333 0.7373 0.7251 0.6906 0.7152 0.7214 0.7619 0.7539 0.7212 0.6911 0.7553 0.7326 0.7121 0.7328 0.742 0.7488 0.726 0.7434 0.763 0.6978 0.7448 0.7504 0.7089 0.7096 0.7495 0.7132 0.7379 0.7004 0.7449 0.7449 0.7203 0.7013 0.7493 0.7067 0.7482 0.7354 0.7446 0.6894 0.7145 0.6986 0.7062 0.7207 0.7158 0.7496 0.7226 0.7211 0.6993 0.7328 0.6892 0.7572 0.6026 0.7545 0.7563 0.7507 0.7334 0.7592 0.7576 0.7474 0.7565 0.7241 0.7371 0.7332 0.7469 0.7283 0.7655 0.7325 0.7404 0.7274 0.7099 0.7439 0.7563 0.7452 0.7631 0.7521 0.745 0.6311 0.7495 0.7316 0.7729 0.7412 0.7476 0.6963 0.7306 0.7534 0.7556 0.764 0.7572 0.7661 0.6875 0.7461 0.6202 0.7265 0.7671 0.731 0.7189 0.7136 0.7164 0.7352 0.705 0.7576 0.7542 0.6732 0.7529 0.7256 0.7491 0.7109 0.7371 0.7419 0.7493 0.6914 0.7356 0.7602 0.7004 0.746 0.7322 0.7122 0.6939 0.7493 0.755 0.7415 0.7222 0.732 0.7157 0.7575 0.7555 0.7574 0.7362 0.7561 0.7662 0.7521 0.7625 0.7452 0.7651 0.7395 0.7462 0.7193 0.7682 0.7567 0.7689 0.7665 0.6902 0.7627 0.7369 0.7596 0.7642 0.7575 0.7431 0.7547 0.7348 0.7326 0.7183 0.7175 0.7515 0.7405 0.7214 0.7616 0.7612 0.7199 0.6988 0.7172 0.7401 0.7331 0.7341 0.7444 0.7402 0.7742 0.7745 0.7415 0.682 0.7465 0.7471 0.7612 0.742 0.7411 0.6966 0.751 0.7476 0.7374 0.7648 0.747 0.7397 0.7636 0.7648 0.7506 0.7285 0.7577 0.7397 0.7768 0.7463 0.7272 0.7657 0.7241 0.7607 0.7561 0.7303 0.754 0.7656 0.7711 0.7642 0.7567 0.7743 0.7642 0.7653 0.6949 0.748 0.749 0.7645 0.7532 0.7166 0.5864 0.7521 0.7513 0.7213 0.7189 0.7736 0.7775 0.7617 0.7382 0.7452 0.7314 0.7561 0.7676 0.765 0.765 0.7547 0.7342 0.7498 0.73 0.7699 0.7556 0.7525 0.7759 0.7512 0.7549 0.7725 0.7491 0.7384 0.7637 0.7312 0.7497 0.7521 0.6912 0.7722 0.7749 0.7254 0.7608 0.7333 0.7544 0.7673 0.7703 0.7686 0.7307 0.7548 0.7758 0.7633 0.7158 0.7541 0.7705 0.7293 0.7448 0.7339 0.7596 0.7581 0.7579 0.7728 0.7345 0.778 0.7301 0.7728 0.7182 0.7514 0.7742 0.7081 0.7616 0.7376 0.7252 0.7704 0.7419 0.7402 0.7668 0.7724 0.7011 0.7673 0.7626 0.7559 0.7136 0.7551 0.7463 0.71 0.737 0.7241 0.7268 0.7758 0.7633 0.6981 0.7719 0.7654 0.7504 0.7367 0.7632 0.7656 0.7173 0.7701 0.7553 0.7754 0.7589 0.7547 0.7513 0.7709 0.7002 0.7563 0.7508 0.7688 0.7678 0.7662 0.7822 0.7656 0.7694 0.7782 0.7519 0.729 0.7741 0.7345 0.7514 0.7616 0.7572 0.772 0.7669 0.7503 0.7507 0.7637 0.7573 0.7473 0.7605 0.7694 0.7415 0.7585 0.7719 0.7589 0.7493 0.7302 0.757 0.7162 0.729 0.7621 0.7531 0.759 0.7833 0.7231 0.7663 0.7614 0.7717 0.761 0.7612 0.7531 0.7558 0.7669 0.7696 0.7653 0.7643 0.7768 0.7408 0.7474 0.7529 0.7746 0.7566 0.7491 0.7518 0.7701 0.7485 0.7582 0.7643 0.7533 0.7552 0.7457 0.7488 0.7635 0.6922 0.7136 0.7487 0.695 0.7302 0.7557 0.7653 0.7613 0.7726 0.7186 0.7761 0.7684 0.7771 0.7617 0.7446 0.7595 0.7677 0.7331 0.7602 0.7705 0.7335 0.7167 0.7768 0.7605 0.7403 0.7425 0.7534 0.7439 0.6857 0.7394 0.781 0.7365 0.7788 0.7388 0.747 0.7787 0.7705 0.7695 0.7236 0.7546 0.7524 0.7684 0.7326 0.7156 0.7299 0.782 0.7633 0.7149 0.7456 0.7513 0.7684 0.7751 0.7635 0.7757 0.7553 0.7338 0.7777 0.7725 0.7756 0.7659 0.7616 0.7392 0.7711 0.7619 0.7528 0.7772 0.7804 0.7613 0.7727 0.7603 0.7578 0.7729 0.7763 0.7715 0.7422 0.7585 0.7564 0.7506 0.7703 0.7562 0.7637 0.7687 0.758 0.7563 0.7782 0.7633 0.7661 0.751 0.7785 0.7853 0.7326 0.7653 0.7724 0.7868 0.7319 0.7564 0.7586 0.7346 0.7849 0.759 0.7897 0.7687 0.7842 0.762 0.7644 0.7652 0.7662 0.7377 0.7673 0.7541 0.7476 0.7719 0.7644 0.757 0.7797 0.7459 0.695 0.7521 0.7612 0.7145 0.7797 0.7793 0.7573 0.7508 0.7672 0.7586 0.7665 0.7887 0.777 0.7513 0.7728 0.7597 0.7433 0.7273 0.7644 0.7889 0.7745 0.7559 0.7769 0.7602 0.7526 0.7648 0.7652 0.744 0.7518 0.7472 0.7603 0.7758 0.7741 0.7785 0.776 0.7786 0.7513 0.7597 0.7489 0.7497 0.7782 0.7727 0.7656 
config:{'task_name': <TaskName.CIFAR: 1>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 1, 'lr_interval': 1000, 'lr': 0.01, 'batch_size': 10, 'device': 'cuda:0', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.QCID: 7>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/qcid/', 'test_mark': '_100', 'comment': ''}

config:{'task_name': <TaskName.CIFAR: 1>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 1, 'lr_interval': 1000, 'lr': 0.01, 'batch_size': 10, 'device': 'cuda:0', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.QCID: 7>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/qcid/', 'test_mark': '_100', 'comment': ''}

config:{'task_name': <TaskName.CIFAR: 1>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 1, 'lr_interval': 1000, 'lr': 0.01, 'batch_size': 10, 'device': 'cuda:0', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.QCID: 7>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/qcid/', 'test_mark': '_100', 'comment': ''}
0.1 0.1208 0.1676 0.1906 0.2841 0.2784 0.3173 0.3083 0.2404 0.3402 
config:{'task_name': <TaskName.CIFAR: 1>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 1, 'lr_interval': 1000, 'lr': 0.01, 'batch_size': 10, 'device': 'cuda:0', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.QCID: 7>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/qcid/', 'test_mark': '_100', 'comment': ''}
0.105 0.1557 0.2268 0.2242 0.2629 0.273 0.2589 0.2989 0.331 0.2803 0.3912 0.3476 0.4271 0.3551 0.3626 0.4039 0.3567 0.4521 0.3923 0.4563 0.4165 0.4558 0.4389 0.5036 0.4082 0.5419 0.4159 0.4764 0.4833 0.4879 0.4668 0.5414 0.5062 0.558 0.5416 0.4697 0.5241 0.5744 0.5442 0.5801 0.5407 0.5336 0.5147 0.4858 0.5393 0.5509 0.5652 0.5396 0.5508 0.5882 0.5797 0.539 0.6115 0.572 0.6383 0.6179 0.6253 0.5989 0.6361 0.6119 0.6004 0.6137 0.5974 0.6499 0.6 0.634 0.659 0.6108 0.6066 0.6163 0.6664 0.6554 0.6382 0.6547 0.6593 0.6141 0.6232 0.6569 0.6224 0.6273 0.6589 0.6028 0.6911 0.6553 0.6091 0.6634 0.6714 0.6495 0.6671 0.633 0.6569 0.6728 0.617 0.6277 0.6705 0.6256 0.6562 0.6774 0.7075 0.6966 0.6592 0.6634 0.7071 0.67 0.6479 0.6246 0.6576 0.6788 0.6938 0.6828 0.6509 0.7096 0.7057 0.667 0.6968 0.684 0.7057 0.6909 0.6996 0.7169 0.6729 0.665 0.6736 0.6723 0.711 0.718 0.6948 0.6893 0.6905 0.7139 0.6911 0.7152 0.6892 0.7022 0.7015 0.7061 0.7033 0.7346 0.7093 0.6714 0.7178 0.7144 0.6977 0.7049 0.7272 0.692 0.692 0.7228 0.688 
config:{'task_name': <TaskName.CIFAR: 1>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 1, 'lr_interval': 1000, 'lr': 0.01, 'batch_size': 10, 'device': 'cuda:0', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.QCID: 7>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/qcid/', 'test_mark': '_100', 'comment': ''}

config:{'task_name': <TaskName.CIFAR: 1>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 1, 'lr_interval': 1000, 'lr': 0.01, 'batch_size': 10, 'device': 'cuda:0', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.QCID: 7>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/qcid/', 'test_mark': '_100', 'comment': ''}
0.1 0.1821 0.2259 0.2329 0.1616 0.2015 0.1708 0.3477 0.2428 0.2255 0.2679 0.2812 0.4 0.3729 0.3258 0.4452 0.4486 0.3807 0.3838 0.4903 0.4831 0.4433 0.4403 0.4914 0.5371 0.5375 0.4964 0.4709 0.458 0.4755 0.569 0.4863 0.5506 0.5535 0.5609 0.5181 0.4832 0.5848 0.589 0.5524 0.5269 0.5122 0.5779 0.5354 0.6089 0.5101 0.5646 0.5683 0.5661 0.6078 0.5868 0.6253 0.5379 0.6585 0.5551 0.6424 0.6318 0.6423 0.6187 0.6041 0.5545 0.6339 0.6529 0.6537 0.4658 0.6129 0.6292 0.6228 0.6485 0.5835 0.6182 0.5828 0.6686 0.6594 0.5798 0.6916 0.6561 0.6473 0.6644 0.6616 0.668 0.6626 0.6916 0.6256 0.5769 0.6236 0.6812 0.6674 0.6763 0.5903 0.6056 0.6939 0.6552 0.6663 0.6611 0.6943 0.6532 0.7179 0.636 0.6674 0.6755 0.5889 0.6457 0.7005 0.6989 0.6607 0.7104 0.6481 0.7059 0.716 0.7069 0.6939 0.6178 0.7002 0.7155 0.6665 0.6602 0.7105 0.6546 0.6715 0.7223 0.6933 0.6963 0.6547 0.6763 0.6771 0.6755 0.7219 0.7196 0.7208 0.7178 0.6794 0.6934 0.6933 0.7208 0.7036 0.6993 0.7067 0.7222 0.6997 0.7115 0.6954 0.7099 0.7115 0.7122 0.7097 0.6922 0.73 0.7194 0.7251 0.7156 0.7096 0.7262 0.7136 0.723 0.7108 0.7136 0.698 0.7382 0.6977 0.7011 0.7365 0.7155 0.6854 0.7365 0.7401 0.7122 0.6837 0.7216 0.6697 0.7388 0.7219 0.7286 0.7195 0.7211 0.7065 0.6863 0.6617 0.7035 0.7481 0.697 0.7295 0.7149 0.685 0.7094 0.6914 0.6682 0.737 0.7282 0.6729 0.69 0.7369 0.696 0.6779 0.7174 0.7534 0.7216 0.711 0.6866 0.7166 0.7454 0.7303 0.7282 0.7176 0.7457 0.6609 0.7284 0.7366 0.7408 0.7023 0.7498 0.7009 0.7217 0.709 0.755 0.7492 0.6742 0.7536 0.7389 0.6974 0.7342 0.7475 0.7001 0.716 0.7446 0.7335 0.7155 0.732 0.7086 0.7243 0.7394 0.7517 0.7126 0.6827 0.6709 0.708 0.7314 0.7152 0.6682 0.7397 0.7409 0.7031 0.6934 0.7284 0.7327 0.7332 0.7571 0.7017 0.6774 0.7169 0.756 0.7235 0.7369 0.7472 0.7411 0.7566 0.7549 0.7476 0.7162 0.6903 0.736 0.7188 0.7468 0.7442 0.7619 0.6616 0.7441 0.7424 0.7375 0.741 0.752 0.7469 0.7531 0.7197 0.7242 0.7417 0.7306 0.7514 0.6954 0.7548 0.7477 0.7097 0.7501 0.7253 0.7343 0.7357 0.7227 0.6996 0.7308 0.7327 0.7432 0.7487 0.753 0.7123 0.7117 0.7069 0.6995 0.6709 0.6809 0.7342 0.7348 0.7389 0.7431 0.7516 0.7362 0.7439 0.7541 0.7549 0.7496 0.7145 0.7674 0.7294 0.7597 0.7345 0.6935 0.7312 0.7084 0.7621 0.7312 0.716 0.7639 0.7456 0.7345 0.7503 0.7452 0.7211 0.7191 0.7534 0.7342 0.759 0.7453 0.7545 0.7303 0.758 0.7344 0.7508 0.7488 0.7504 0.7418 0.7337 0.7363 0.7387 0.7584 0.7185 0.7151 0.7492 0.7545 0.7464 0.721 0.7382 0.7434 0.7443 0.7698 0.7099 0.7388 0.7122 0.7336 0.7316 0.7455 0.757 0.7549 0.7328 0.7339 0.7155 0.7564 0.7458 0.7583 0.6979 0.7524 0.7603 0.7196 0.7303 0.7345 0.7514 0.7336 0.7598 0.7478 0.6687 0.7634 0.724 0.7327 0.7565 0.7111 0.7462 0.7489 0.6908 0.7457 0.7615 0.7599 0.7249 0.7565 0.7619 0.685 0.7717 0.7696 0.7431 0.7384 0.7485 0.7481 0.7362 0.749 0.7607 0.7333 0.7499 0.7022 0.7518 0.7537 0.7517 0.7634 0.7433 0.7402 0.7602 0.7676 0.7254 0.7453 0.7676 0.7299 0.7504 0.7665 0.7578 0.7292 0.7523 0.7672 0.7398 0.74 0.746 0.7514 0.747 0.7507 0.7465 0.7387 0.6574 0.7192 0.7569 0.7724 0.71 0.7681 0.7268 0.7157 0.7456 0.7608 0.7577 0.743 0.7325 0.7538 0.7046 0.772 0.7514 0.716 0.7542 0.7376 0.7134 0.7276 0.7487 
config:{'task_name': <TaskName.CIFAR: 1>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 1, 'lr_interval': 1000, 'lr': 0.01, 'batch_size': 10, 'device': 'cuda:0', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.QCID: 7>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/qcid/', 'test_mark': '_100', 'comment': ''}
0.1 0.1153 0.1556 0.1735 0.2273 0.2871 0.2788 0.3161 0.2787 0.341 0.2876 0.329 0.4273 0.3247 0.3509 0.3484 0.4738 0.3615 0.4977 0.4388 0.4267 0.4399 0.4539 0.4769 0.4773 0.4714 0.534 0.4213 0.4595 0.4602 0.384 0.4905 0.535 0.5488 0.546 0.4381 0.5368 0.5504 0.5535 0.5014 0.5956 0.5538 0.5093 0.5813 0.5847 0.5572 0.4853 0.5942 0.6175 0.5513 0.5771 0.6314 0.5635 0.5489 0.6317 0.6054 0.5815 0.5728 0.6404 0.5517 0.6216 0.6365 0.6461 0.5597 0.6482 0.5978 0.5644 0.6269 0.5625 0.6415 0.6524 0.6491 0.5789 0.5449 0.5028 0.5846 0.6306 0.5829 0.6339 0.4415 0.6677 0.5268 0.6185 0.6153 0.6051 0.6089 0.5996 0.6501 0.6158 0.4896 0.6731 0.6319 0.5399 0.6777 0.6247 0.6352 0.6735 0.6514 0.6268 0.6808 0.6544 0.6442 0.6524 0.6374 0.6415 0.6179 0.7087 0.6381 0.6957 0.6177 0.6626 0.6747 0.6975 0.6946 0.6897 0.6398 0.6783 0.683 0.6675 0.6627 0.6451 0.7048 0.6535 0.6788 0.6883 0.678 0.6678 0.6844 0.6468 0.6921 0.6983 0.7108 0.678 0.6477 0.7021 0.7056 0.6818 0.6822 0.6542 0.7168 0.6815 0.7033 0.6978 0.6873 0.6285 0.6763 0.6963 0.7057 0.671 0.7069 0.6893 0.6979 0.6591 0.7016 0.7013 0.7343 0.7202 0.6951 0.7083 0.7036 0.6944 0.6733 0.6742 0.7088 0.6973 0.71 0.7267 0.6875 0.6638 0.6783 0.7321 0.7035 0.7048 0.7398 0.707 0.7253 0.6844 0.7067 0.6679 0.6832 0.6525 0.7282 0.7302 0.6752 0.6965 0.6694 0.7217 0.7004 0.7371 0.6873 0.6986 0.6984 0.7158 0.7229 0.6826 0.7269 0.733 0.723 0.7166 0.7118 0.6984 0.6228 0.692 0.7207 0.731 0.7474 0.7166 0.7423 0.7068 0.6787 0.7434 0.7274 0.7429 0.7243 0.7482 0.7353 0.7103 0.734 0.7417 0.6775 0.7327 0.7429 0.7298 0.7071 0.7222 0.7327 0.7161 0.7068 0.7033 0.7492 0.7078 0.6734 0.7248 0.7421 0.6816 0.7399 0.6622 0.7051 0.7445 0.7225 0.7196 0.7238 0.7219 0.7545 0.7128 0.7203 0.7349 0.7216 0.7449 0.7256 0.739 0.7514 0.7501 0.732 0.7446 0.6945 0.7452 0.7263 0.7267 0.7338 0.7382 0.7124 0.7344 0.6737 0.7437 0.7509 0.7351 0.7562 0.7328 0.6874 0.6707 0.7461 0.6706 0.7548 0.7314 0.7462 0.7175 0.6371 0.7332 0.7575 0.7203 0.7129 0.7053 0.767 0.7355 0.7006 0.7577 0.7072 0.7409 0.7292 0.7446 0.7387 0.7394 0.7251 0.6905 0.7037 0.7429 0.7353 0.7129 0.7233 0.7371 0.6892 0.6747 0.7591 0.7134 0.7582 0.7449 0.7251 0.7092 0.7365 0.7479 0.7426 0.7128 0.7265 0.673 0.7592 0.7322 0.7331 0.7277 0.7594 0.7473 0.7298 0.6409 0.7107 0.7337 0.7022 0.7594 0.7624 0.7604 0.7541 0.7355 0.7269 0.7448 0.7253 0.7117 0.7153 0.764 0.7319 0.7415 0.7433 0.7179 0.771 0.7217 0.7544 0.754 0.7377 0.7133 0.6958 0.7473 0.7415 0.7376 0.7505 0.7367 0.7313 0.7441 0.7456 0.6933 0.6986 0.7598 0.7242 0.7077 0.7615 0.7429 0.6598 0.7361 0.7296 0.7469 0.7178 0.7143 0.7334 0.758 0.7536 0.6572 0.7199 0.7303 0.7163 0.7224 0.756 0.7056 0.7273 0.7375 0.6961 0.7066 0.7282 0.7235 0.763 0.7474 0.7549 0.7692 0.7435 0.7399 0.7563 0.7662 0.6461 0.7416 0.7363 0.7127 0.7341 0.7531 0.7274 0.7617 0.746 0.7402 0.7584 0.7506 0.6279 0.7523 0.7717 0.7572 0.7491 0.7496 0.7504 0.7541 0.7212 0.7443 0.7466 0.7344 0.7198 0.7498 0.7622 0.7604 0.7038 0.7164 0.7309 0.7592 0.759 0.7209 0.766 0.7662 0.754 0.756 0.6284 0.7143 0.7665 0.7471 0.7412 0.762 0.7417 0.7665 0.7529 0.7059 0.6893 0.7091 0.7534 0.7576 0.7458 0.7562 0.7296 0.7417 0.7576 0.7582 0.6815 0.7679 0.7116 0.7468 0.7583 0.7639 0.7633 0.731 0.7473 0.7632 0.7401 0.6988 0.7491 0.7381 0.6985 0.7772 0.699 0.7451 0.7478 0.768 0.7452 0.7645 0.7172 0.7277 0.7463 0.757 0.7199 0.7249 0.7505 0.7698 0.7683 0.767 0.7429 0.7587 0.7628 0.7533 0.7486 0.7558 0.7408 0.727 0.7599 0.7318 0.7662 0.7595 0.7737 0.7582 0.7127 0.7586 0.6927 0.7628 0.7211 0.7463 0.7468 0.7664 0.7066 0.7568 0.7306 0.7424 0.7558 0.7612 0.7721 0.7359 0.7785 0.7651 0.7475 0.7374 0.776 0.7501 0.748 0.7311 0.7599 0.7658 0.7748 0.7603 0.722 0.7576 0.7237 0.7077 0.7691 0.7771 0.7787 0.6991 0.7515 0.7601 0.7593 0.7426 0.7377 0.7632 0.7606 0.7687 0.765 0.7417 0.671 0.7595 0.7507 0.7607 0.765 0.7652 0.7521 0.6629 0.7338 0.7633 0.7729 0.768 0.7705 0.7525 0.7817 0.7202 0.7055 0.7398 0.7432 0.7613 0.7802 0.7565 0.7631 0.7382 0.7568 0.6965 0.774 0.7674 0.753 0.7619 0.738 0.7404 0.7545 0.7597 0.7187 0.7496 0.7458 0.7653 0.7682 0.7712 0.7742 0.7569 0.7447 0.7197 0.7271 0.7527 0.7695 0.7616 0.7685 0.7725 0.765 0.734 0.7546 0.758 0.7631 0.7424 0.7592 0.7465 0.7421 0.7612 0.7733 0.7616 0.7803 0.7363 0.7524 0.7627 0.6308 0.7378 0.7397 0.7285 0.7604 0.7607 0.7427 0.7346 0.7536 0.7384 0.7655 0.7623 0.7704 0.7586 0.7054 0.7443 0.7521 0.7433 0.7605 0.7697 0.7668 0.7709 0.7498 0.7625 0.744 0.7562 0.7587 0.7397 0.7419 0.7195 0.6829 0.7402 0.7375 0.7115 0.7705 0.7123 0.7322 0.7727 0.7584 0.7533 0.7347 0.7388 0.7676 0.7693 0.7624 0.7691 0.7483 0.7344 0.7544 0.7351 0.7252 0.7421 0.7623 0.741 0.6426 0.7829 0.766 0.7428 0.7627 0.7848 0.7726 0.7738 0.7652 0.7362 0.7577 0.7692 0.7846 0.7726 0.7813 0.7743 0.7429 0.7647 0.7705 0.7664 0.7797 0.7301 0.7604 0.7204 0.7742 0.7737 0.7456 0.7536 0.7401 0.7122 0.7023 0.749 0.7756 0.7508 0.7784 

config:{'task_name': <TaskName.CIFAR: 1>, 'server_num': 2, 'client_num': 200, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 1, 'lr_interval': 1000, 'lr': 0.01, 'batch_size': 10, 'device': 'cuda:1', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.QCID: 7>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/qcid/', 'test_mark': '_200', 'comment': ''}

config:{'task_name': <TaskName.CIFAR: 1>, 'server_num': 2, 'client_num': 200, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 1, 'lr_interval': 1000, 'lr': 0.01, 'batch_size': 10, 'device': 'cuda:1', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.QCID: 7>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/qcid/', 'test_mark': '_200', 'comment': ''}
0.1 0.1621 0.2166 0.2671 0.2983 0.2938 0.3068 0.2951 0.3003 0.3696 0.3732 0.4089 0.3844 0.4697 0.4729 0.5019 0.4832 0.4944 0.5065 0.529 0.561 0.472 0.5187 0.5254 0.5704 0.5912 0.5528 0.5776 0.551 0.5151 0.5552 0.5972 0.6115 0.5356 0.5928 0.6139 0.6327 0.5933 0.6004 0.6435 0.6023 0.6428 0.6202 0.6226 0.671 0.6706 0.6521 0.6213 0.6547 0.6451 0.6394 0.6808 0.6664 0.6444 0.6464 0.6598 0.6637 0.6704 0.6909 0.6539 0.6658 0.6978 0.6677 0.6833 0.6791 0.6922 0.6825 0.7028 0.655 0.7208 0.7085 0.6777 0.6923 0.7162 0.6754 0.6663 0.7264 0.7038 0.7111 0.7104 0.6982 0.7172 0.7161 0.6951 0.6734 0.7051 0.7124 0.7117 0.7285 0.7083 0.7032 0.7202 0.7169 0.726 0.7166 0.7289 0.7192 0.7341 0.6875 0.7246 0.7376 0.7163 0.7125 0.7555 0.7256 0.7434 0.7062 0.7222 0.7277 0.7285 0.735 0.725 0.7007 0.7172 0.7338 0.7296 0.7511 0.7642 0.7459 0.7496 0.7362 0.6879 0.7572 0.7439 0.7494 0.7628 0.743 0.7725 0.7306 0.745 0.7709 0.7497 0.7684 0.7401 0.7556 0.759 0.7474 0.7279 0.7535 0.7378 0.7326 0.7502 0.7277 0.7618 0.764 0.7501 0.7517 0.7464 0.757 0.7706 0.7677 0.7474 0.7596 0.7599 0.7768 0.7506 0.7571 0.776 0.764 0.7275 0.7398 0.748 0.77 0.7478 0.7418 0.7576 0.7591 0.7607 0.7539 0.7702 0.7852 0.7649 0.775 0.7605 0.7543 0.7299 0.7837 0.7617 0.7753 0.7511 0.7707 0.7267 0.7671 0.7757 0.7729 0.783 0.7342 0.7399 0.7657 0.7812 0.7784 0.7716 0.7758 0.7658 0.7825 0.762 0.7668 0.7492 0.7416 0.7668 0.7836 0.7489 0.7453 0.7897 0.7458 0.7693 0.7936 0.7841 0.7824 0.7786 0.7797 0.7923 0.7904 0.7474 0.7943 0.7936 0.7668 0.7824 0.747 0.7786 0.7784 0.7843 0.7736 0.7853 0.7655 0.7775 0.7692 0.7852 0.7694 0.7855 0.7667 0.7421 0.7749 0.7876 0.7879 0.722 0.766 0.7793 0.7831 0.7539 0.7904 0.7974 0.7823 0.7899 0.7712 0.7228 0.7546 0.7916 0.773 0.7644 0.7506 0.7672 0.7941 0.7757 0.7836 0.7606 0.7538 0.7887 0.797 0.7705 0.7788 0.7217 0.7767 0.7753 0.7765 0.7912 0.7773 0.7812 0.8008 0.7904 0.7813 0.7717 0.7944 0.789 0.7702 0.7942 0.7836 0.7854 0.7887 0.7938 0.7881 0.7673 0.7841 0.7968 0.7762 0.7777 0.8057 0.7866 0.7823 0.7806 0.7745 0.7858 0.7921 0.7958 0.7796 0.7986 0.7711 0.79 0.794 0.7852 0.7678 0.7975 0.8027 0.7962 0.7942 0.7902 0.789 0.7942 0.8045 0.7788 0.7858 0.7774 0.7797 0.7939 0.7678 0.7612 0.811 0.8055 0.7982 0.8013 0.8096 0.7922 0.7963 0.7922 0.7978 0.7836 0.8066 0.8027 0.7952 0.7873 0.7947 0.8084 0.7617 0.7841 0.8042 0.7993 0.8069 0.7849 0.7685 0.7742 0.7975 0.8063 0.7966 0.7885 0.7981 0.7987 0.7971 0.8034 0.7842 0.7957 0.8088 0.7881 0.7849 0.799 0.8166 0.7834 0.8022 0.799 0.8164 0.7821 0.7965 0.8125 0.7859 0.7968 0.8027 0.802 0.8055 0.7919 0.8062 0.7952 0.8137 0.7683 0.8029 0.7885 0.8047 0.7854 0.7916 0.7813 0.8038 0.8147 0.7905 0.818 0.7818 0.7985 0.8035 0.7953 0.7992 0.7921 0.7772 0.7992 0.7693 0.8099 0.7992 0.7874 0.8111 0.7987 0.8094 0.8008 
config:{'task_name': <TaskName.CIFAR: 1>, 'server_num': 2, 'client_num': 200, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 1, 'lr_interval': 1000, 'lr': 0.01, 'batch_size': 10, 'device': 'cuda:1', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.QCID: 7>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/qcid/', 'test_mark': '_200', 'comment': ''}

config:{'task_name': <TaskName.CIFAR: 1>, 'server_num': 2, 'client_num': 200, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 1, 'lr_interval': 1000, 'lr': 0.01, 'batch_size': 10, 'device': 'cuda:1', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.QCID: 7>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/qcid/', 'test_mark': '_200', 'comment': ''}

config:{'task_name': <TaskName.CIFAR: 1>, 'server_num': 2, 'client_num': 200, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 1, 'lr_interval': 1000, 'lr': 0.01, 'batch_size': 10, 'device': 'cuda:1', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.QCID: 7>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/qcid/', 'test_mark': '_200', 'comment': ''}
0.0947 0.1363 0.2508 0.2542 0.2279 
config:{'task_name': <TaskName.CIFAR: 1>, 'server_num': 2, 'client_num': 200, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 1, 'lr_interval': 1000, 'lr': 0.01, 'batch_size': 10, 'device': 'cuda:0', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.QCID: 7>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/qcid/', 'test_mark': '_200', 'comment': ''}
0.0999 0.1641 0.2182 0.2287 0.2868 0.2761 0.3645 0.3554 0.3893 0.3664 0.4009 0.4218 0.464 0.4244 0.3696 0.4684 0.4992 0.5121 0.5122 0.516 0.5381 0.5329 0.5664 0.5641 0.5652 0.5893 0.5328 0.5392 0.6027 0.6022 0.5871 0.578 0.5894 0.6093 0.6011 0.6285 0.6256 0.6086 0.6067 0.6275 0.6509 0.6791 0.6306 0.6459 0.646 0.676 0.651 0.6743 0.6712 0.6768 0.6867 0.6768 0.6665 0.691 0.7006 0.6999 0.688 0.7135 0.6679 0.6875 0.673 0.6704 0.7338 0.6749 0.7242 0.725 0.6804 0.7193 0.7099 0.7101 0.7385 0.7165 0.7114 
config:{'task_name': <TaskName.CIFAR: 1>, 'server_num': 2, 'client_num': 200, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 1, 'lr_interval': 1000, 'lr': 0.01, 'batch_size': 10, 'device': 'cuda:0', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.QCID: 7>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/qcid/', 'test_mark': '_200', 'comment': ''}

config:{'task_name': <TaskName.CIFAR: 1>, 'server_num': 2, 'client_num': 200, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 1, 'lr_interval': 1000, 'lr': 0.01, 'batch_size': 10, 'device': 'cuda:0', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.QCID: 7>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/qcid/', 'test_mark': '_200', 'comment': ''}
0.1 0.1155 0.1788 0.2416 0.2835 0.3119 0.3091 0.3024 0.3576 0.3729 0.4004 0.452 0.4299 0.4092 0.467 0.4474 0.4631 0.5036 0.4455 0.5387 0.5004 0.5006 0.5716 0.5343 0.5537 0.5223 0.5712 0.5989 0.5307 0.566 0.5886 0.5543 0.5569 0.5924 0.5768 0.6248 0.6167 0.5843 0.5757 0.6447 0.6068 0.6205 0.6291 0.6069 0.6154 0.6573 0.6418 0.6093 0.6129 0.6309 0.6224 0.6235 0.6651 0.6654 0.6667 0.6633 0.6639 0.6609 0.6483 0.6412 0.676 0.6618 0.6433 0.6851 0.6425 0.6591 0.6261 0.6499 0.6827 0.7091 0.677 0.6673 0.7009 0.6997 0.6883 0.6837 0.6694 0.7065 0.7214 0.6702 0.6642 0.6856 0.7199 0.6765 0.7134 0.7128 0.7211 0.699 0.6957 0.6797 0.7121 0.665 0.7341 0.7059 0.7214 0.712 0.7188 0.7082 0.6963 0.726 0.6952 0.7285 0.7048 0.742 0.7382 0.7369 0.7189 0.7313 0.7388 0.7154 0.7234 0.7233 0.7349 0.7254 0.7387 0.7381 0.7313 0.7324 0.7554 0.7366 0.7433 0.7564 0.7486 0.7316 0.719 0.7557 0.7369 0.7552 0.7074 0.7459 0.7516 0.7456 0.7506 0.7183 0.739 0.7146 0.7283 0.7216 0.7377 0.741 0.7487 0.7363 0.755 0.7602 0.7301 0.7671 0.7423 0.7493 0.7544 0.7397 0.739 0.7614 0.7679 0.7523 0.7571 0.738 0.7473 0.7654 0.7589 0.7544 0.7694 0.7478 0.7261 0.745 0.7682 0.7453 0.7629 0.7501 0.7616 0.7636 0.7602 0.7227 0.779 0.7713 0.7792 0.7224 0.7757 0.7712 0.7688 0.7441 0.7701 0.7623 0.759 0.7658 0.7731 0.7483 0.7525 0.7618 0.7593 0.7285 0.7732 0.7662 0.779 0.768 0.7724 0.7826 0.7742 0.7669 0.7628 0.7428 0.7714 0.7257 0.7779 0.78 0.7885 0.791 0.7862 0.7685 0.7648 0.7707 0.7728 0.786 0.7592 0.7784 0.7807 0.7708 0.7816 0.7802 0.7717 0.7561 0.7863 0.7647 0.7725 0.7718 0.7869 0.7491 0.764 0.7663 0.7729 0.7755 0.7676 
config:{'task_name': <TaskName.CIFAR: 1>, 'server_num': 2, 'client_num': 200, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 1, 'lr_interval': 1000, 'lr': 0.01, 'batch_size': 10, 'device': 'cuda:0', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.QCID: 7>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/qcid/', 'test_mark': '_200', 'comment': ''}
0.1072 0.1011 0.1199 0.2117 0.1755 0.2069 0.3021 0.3744 0.3056 0.3058 0.3627 0.3825 0.402 0.3411 0.3681 0.4214 0.4619 0.4725 0.4308 0.501 0.4399 0.474 0.4735 0.5157 0.4574 0.5275 0.5619 0.5608 0.5627 0.5596 0.5835 0.5678 0.574 0.5073 0.5622 0.6191 0.5888 0.598 0.6472 0.5911 0.623 0.6062 0.6093 0.6254 0.6511 0.6357 0.6473 0.6533 0.6401 0.6656 0.6807 0.6579 0.6657 0.5725 0.6748 0.6594 0.665 0.6899 0.6763 0.6466 0.6805 0.6699 0.6574 0.6451 0.6716 0.6912 0.6897 0.7055 0.6558 0.6498 0.6636 0.6999 0.6852 0.6789 0.6529 0.708 0.6852 0.7036 0.7022 0.6668 0.6671 0.7067 0.6448 0.6941 0.6935 0.7179 0.7195 0.7408 0.7158 0.6931 0.7136 0.659 0.72 0.7361 0.7363 0.7313 0.7403 0.7451 0.735 0.7273 0.7161 0.713 0.7393 0.7308 0.7385 0.7501 0.7414 0.716 0.7482 0.7243 0.7346 0.7264 0.7565 0.7425 0.7244 0.725 0.7538 0.7146 0.7497 0.7529 0.7547 0.7262 0.7218 0.7574 0.7238 0.7136 0.7443 0.7559 0.7304 0.7687 0.7441 0.752 0.7608 0.7647 0.7811 0.7613 0.7647 0.7769 0.7403 0.7672 0.7474 0.7752 0.7665 0.769 0.7824 0.7673 0.7424 0.742 0.7637 0.7827 0.7683 0.7286 0.7891 0.763 0.7864 0.748 0.7514 0.7796 0.7671 0.7437 0.7715 0.7747 0.7867 0.7806 0.7738 0.7665 0.7636 0.7595 0.7755 0.7674 0.782 0.7676 0.7703 0.7351 0.7645 0.7798 0.7866 0.7913 0.7667 0.7802 0.7657 0.7397 0.7719 0.7685 0.7835 0.7855 0.7792 0.791 0.7937 0.7728 0.786 0.78 0.747 0.7841 0.7488 0.7629 0.7881 0.7902 0.7576 0.7829 0.763 0.7848 0.7453 0.7775 0.7496 0.7972 0.7663 0.7626 0.7676 0.7755 0.7905 0.7633 0.7585 0.7971 0.779 0.7923 0.7476 0.7922 0.7618 0.764 0.7891 0.7737 0.7662 0.7865 0.7948 0.7746 0.7794 0.7979 0.7815 0.7571 0.7855 0.7833 0.7768 0.789 0.7862 0.7631 0.74 0.7993 0.793 0.7535 0.7291 0.7892 0.7881 0.7426 0.7766 0.7838 0.7678 0.7503 0.783 0.7804 0.7995 0.8013 0.7552 0.7693 0.7834 0.7803 0.7847 0.7726 0.7803 0.7776 0.7956 0.7581 0.7921 0.7686 0.7805 0.7954 0.7949 0.7525 0.7952 0.7331 0.7933 0.7892 0.7472 0.7802 0.7754 0.793 0.8002 0.7892 0.7882 0.7915 0.8078 0.8002 0.8084 0.8091 0.7877 0.8005 0.7986 0.7989 0.7944 0.8009 0.7901 0.8037 0.7991 0.8025 0.7895 0.7662 0.7684 0.7783 0.8074 0.8162 0.793 0.7923 0.7969 0.7363 0.7954 0.7799 0.7869 0.8018 0.7843 0.8115 0.78 0.7886 0.8018 0.7931 0.8063 0.799 0.8063 0.7929 0.8062 0.7917 0.7742 0.75 0.8036 0.8101 0.8027 0.7994 0.7953 0.8105 0.7665 0.7808 0.771 0.7749 0.7954 0.8108 0.7913 0.7996 0.7692 0.7932 0.797 0.7961 0.8085 0.8126 0.7566 0.7819 0.7988 

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda:3', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda:3', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda:3', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda:3', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda:3', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda:3', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda:3', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda:3', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda:3', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda:3', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda:3', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda:3', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda:3', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda:3', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda:3', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda:3', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda:3', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}
0.2447 0.3754 0.4491 0.4999 0.5109 0.5103 0.4602 0.5679 0.6251 0.6223 0.6267 0.6242 
config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda:3', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}
0.1667 0.4829 0.6213 0.6367 0.598 0.6246 0.7019 0.715 0.7428 0.6855 0.7029 0.7294 0.7527 0.7822 0.7808 0.7752 0.7831 0.7641 0.8052 0.793 0.8038 0.7612 0.8057 0.7304 0.7686 0.8128 0.7655 0.8088 0.7973 0.8097 0.7828 0.8165 0.8249 0.8154 0.7455 0.8058 0.7879 0.7938 0.7901 0.832 0.7906 0.7905 0.8041 0.8191 0.811 0.8165 0.8157 0.807 0.7967 0.8027 0.8254 0.8282 0.8022 0.8162 0.8158 0.8272 0.8092 0.7884 0.7839 0.8186 0.8121 0.8257 0.8283 0.8185 0.7825 0.8215 0.8276 0.7869 0.8182 0.8359 0.8332 0.8385 0.8241 0.8101 0.8211 0.8115 0.8344 0.7956 0.8263 0.7789 0.842 0.8359 0.8427 0.8251 0.7868 0.7861 0.8332 0.8305 0.8193 0.8334 0.8254 0.819 0.8234 0.8366 0.8197 0.8401 0.8229 0.8122 0.8436 0.8185 0.8352 0.8186 0.8372 
config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (20, 201), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}
0.175 0.3562 0.4356 0.5479 0.5658 0.6072 0.5912 0.6972 0.6351 0.642 0.6694 0.6422 0.6755 0.6875 0.7026 0.7014 0.6815 0.7005 0.709 0.6567 0.6844 0.7717 0.6275 0.6521 0.7139 0.7494 0.7789 0.67 0.6785 0.6923 0.7504 0.7393 0.7398 0.7535 0.7338 0.7541 0.7328 0.7167 0.789 0.7835 0.7824 0.7697 0.7733 0.7615 0.7577 0.7848 0.7539 0.7893 0.7706 0.8118 0.7951 0.7902 0.8008 0.7526 0.7149 0.7767 0.7801 0.7847 0.7762 0.7955 0.8043 0.7755 0.8066 0.7953 0.7889 0.8123 0.7864 0.7912 0.7754 0.7534 0.8188 0.8021 0.7681 0.7542 0.8142 0.7865 0.7884 0.795 0.8194 0.7736 0.7684 0.8081 0.8104 0.8203 0.7929 0.7978 0.8028 0.7956 0.7947 0.7862 0.7789 0.7874 0.7914 0.813 0.8056 0.8194 0.7993 0.8015 0.8122 0.8318 0.8095 0.8088 0.7863 0.8127 0.8196 0.7938 0.8323 0.8333 0.8234 0.8222 0.772 0.7996 0.8114 0.8188 0.8076 0.8037 0.8288 0.7849 0.8304 0.8065 0.8272 0.8255 0.8396 0.7879 0.7732 0.8069 0.8067 0.8317 0.8245 0.7889 0.7994 0.83 0.8305 0.8274 0.8319 0.8077 0.8304 0.8325 0.8216 0.8192 0.823 0.8241 0.8353 0.8302 0.8353 0.8129 0.8016 0.8283 0.8144 0.834 0.8031 0.8304 0.8256 0.8174 0.8337 0.8288 0.8204 0.7971 0.8374 0.8131 0.8214 0.8064 0.8039 0.8264 0.8214 0.8383 0.817 0.8361 0.8378 0.7975 0.8426 0.8294 0.8087 0.8108 0.8301 0.838 0.819 0.8262 0.8312 0.827 0.8092 
config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 101), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 101), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 101), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}
0.1598 0.1619 0.3532 0.3652 0.3846 0.5775 0.4929 0.5492 0.5934 0.6213 0.6244 0.6811 0.6544 0.6281 0.6313 0.6719 0.7416 
config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 101), 'alpha': (0.01, 0.01), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 10, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}
0.146 0.2532 0.2596 0.2754 0.2028 0.1996 0.2445 0.2079 0.3789 0.314 0.2451 0.3618 0.4054 0.284 0.3852 0.3316 0.3449 0.3769 0.3805 0.2899 0.3466 0.3445 0.3881 0.3847 0.3504 0.3578 0.3191 0.4408 0.3149 0.3314 0.3053 0.3761 0.345 0.3349 0.3974 0.4154 0.3844 0.3526 0.3442 0.4171 0.4797 0.4017 0.4884 0.5304 0.477 0.3409 0.407 0.4328 
config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 101), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 10, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}
0.1827 0.3797 0.4147 0.5508 0.5555 0.6273 0.5974 0.6134 0.678 
config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 51), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 10, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}
0.1581 0.2575 0.2433 0.3975 0.428 0.2977 0.4665 0.5722 0.5719 0.4999 0.6409 0.4969 0.6022 0.5299 0.5248 0.6149 0.4933 0.5833 0.5814 0.5977 0.644 0.5739 0.5765 0.6114 0.6008 0.7062 0.5331 0.5838 0.6536 0.6096 0.5519 0.6904 0.6726 0.6221 0.6487 0.6218 0.6778 0.6795 0.6439 0.703 0.6969 0.6562 0.6816 0.6569 0.7288 0.684 0.7089 0.6669 0.7132 0.7189 0.7048 0.732 0.7 0.6998 0.6605 0.7028 0.7017 0.7038 0.7521 0.7106 0.6595 0.6629 0.6875 0.7122 0.7255 0.7228 0.6709 0.738 0.7384 0.7013 0.7187 0.7405 0.7286 0.7058 0.6921 0.7169 0.6625 0.7299 0.7194 0.7223 0.6525 0.718 0.6186 0.7096 0.7145 0.7211 0.7265 0.6841 0.7424 0.765 0.6868 0.7261 0.6104 0.6413 0.7141 0.7346 0.7422 0.7294 0.6762 0.7222 0.697 0.7426 0.6507 0.688 0.7462 0.7222 0.7053 0.7581 0.7577 0.7279 0.7359 0.7505 0.7322 0.7678 0.7198 0.7474 0.7406 0.7561 0.6938 0.7505 0.7313 0.7016 0.7133 0.7296 0.7322 0.7498 0.743 0.7233 0.7548 0.7269 0.7612 0.7144 0.7498 0.7037 0.7571 0.7433 0.7167 0.7071 0.6921 0.7602 0.7386 0.738 0.6982 0.7604 0.7497 0.7049 0.7466 0.7418 0.7584 0.762 0.7635 0.7672 0.7477 0.7589 0.7236 0.7157 0.7459 0.7617 0.7335 0.7528 0.7501 0.7686 0.7256 0.764 0.6942 0.757 0.7492 0.7124 0.752 0.6395 0.7763 0.6803 0.7588 0.7505 0.7372 0.761 0.7491 0.7271 0.7621 0.714 0.7145 0.7706 0.7225 0.7077 0.727 
config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 51), 'alpha': (0.1, 0.1), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 10, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}
0.1385 0.1869 0.1712 0.2002 0.2621 0.3936 0.3511 0.4262 0.4619 0.3913 0.3355 0.4647 0.3923 0.527 0.4444 0.5713 0.626 0.5722 0.6288 0.583 0.5833 0.5632 0.5907 0.6008 0.6639 0.6728 0.682 0.6475 0.6822 0.6916 0.6743 0.6805 0.6658 0.6426 0.6535 0.7172 0.6683 0.6981 0.6585 0.6862 0.6981 0.6779 0.6757 0.6525 0.723 0.6879 0.7271 0.6875 0.6859 0.7266 0.6775 0.6788 0.7377 0.7066 0.6727 0.672 0.7241 0.7402 0.7088 0.7061 0.7241 0.7149 0.6885 0.7223 0.6932 0.7288 0.6701 0.7599 0.7266 0.7104 0.7233 0.7127 0.6893 0.6978 0.7361 0.738 0.7388 0.7229 0.7304 0.7122 0.721 0.7256 0.6669 0.717 0.7172 0.7404 0.6668 0.7438 0.7281 0.7111 0.7523 0.6988 0.6516 0.7428 0.7451 0.7329 0.6809 0.7091 0.7284 0.7227 0.7369 0.7521 0.7588 0.7576 0.7366 0.7251 0.7584 0.7336 0.7153 0.7375 0.7405 0.7343 0.6478 0.7338 0.7257 0.7521 0.7482 0.7395 0.7465 0.7435 0.7224 0.7191 0.7167 0.7532 0.7603 0.7658 0.7379 0.7557 0.7373 0.7596 0.7334 0.6904 0.7021 0.7387 0.7634 0.7405 0.71 0.7469 0.7152 0.7452 0.7292 0.7371 0.7521 0.7312 0.6913 0.7318 0.7693 0.7348 0.7394 0.7488 0.6882 0.7313 0.7592 0.7553 0.7666 0.7455 0.7513 0.7432 0.7356 0.7227 0.7012 0.7106 0.7564 0.7324 0.7388 0.7378 0.7354 0.7204 0.7592 0.7488 0.7266 0.7513 0.7527 0.7586 0.7708 0.748 0.7532 0.7049 0.7327 0.7603 0.7478 0.7129 0.7039 0.7604 0.7679 0.7372 0.7616 0.7518 0.7661 0.7436 
config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 51), 'alpha': (0.05, 0.05), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 10, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}

config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 51), 'alpha': (0.05, 0.05), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 10, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 10, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}
0.191 0.2434 0.1798 0.2466 0.3305 0.3156 0.4266 0.4307 0.3657 0.3764 0.4957 
config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 51), 'alpha': (0.05, 0.05), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 5, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}
0.164 0.2483 0.2861 0.3274 0.2926 0.2696 0.2869 0.3692 0.3683 0.3329 0.3354 0.3488 0.3401 0.5072 0.4136 0.4572 0.4383 0.3765 0.453 0.4884 0.4898 0.438 0.4846 0.5317 0.4949 0.5333 0.5008 0.4695 0.5144 0.4901 0.6044 0.4641 0.5095 0.5808 0.5368 0.4403 0.5189 0.5348 0.5257 0.5249 0.5883 0.6012 0.6015 0.6037 0.5393 0.4955 0.6131 0.4671 0.5607 0.5866 0.5508 0.5342 0.5411 0.5759 0.6502 0.5573 0.5337 0.5339 0.5427 0.5974 0.558 0.6419 0.5876 0.5346 0.5495 0.5736 0.5247 0.6026 0.5732 0.4923 0.5407 0.6224 0.5869 0.6056 0.5737 0.5975 0.6016 0.5569 0.6341 0.6552 0.5606 0.5773 0.6245 0.6023 0.5665 0.6382 0.5681 0.6209 0.6072 0.5667 0.6143 0.6293 0.5977 0.5842 0.5513 0.627 0.6373 0.5529 0.6479 0.6145 0.6365 0.6425 0.6204 0.5748 0.6024 0.6117 0.6323 0.6613 0.5932 0.5853 0.6811 0.6806 0.6286 0.6095 0.6793 0.5156 0.6182 0.6111 0.558 0.6375 0.6345 0.6566 0.5807 0.6765 0.6558 0.6393 0.678 0.6221 0.6338 0.659 0.6819 0.6234 0.6244 0.6398 0.7046 0.6866 0.6194 0.5618 0.609 0.5886 0.6551 0.5992 0.6184 0.6185 0.577 0.6355 0.6001 0.65 0.6464 0.5838 0.5744 0.6471 0.6519 0.6305 0.6279 0.6943 0.6472 0.6054 0.6402 0.6111 0.6687 0.651 0.6811 0.6457 0.683 0.6675 0.692 0.6319 0.6553 0.6166 0.6447 0.6181 0.6699 0.666 0.6626 0.6387 0.6768 0.6664 0.6337 0.7045 0.6386 0.7053 0.6552 0.64 0.6592 0.6587 0.6462 0.6368 0.686 0.6526 0.6378 0.6526 0.6897 0.6741 0.6891 0.6313 0.6501 0.673 0.6856 0.6314 0.6583 0.6555 0.7013 0.5887 0.6661 0.6563 0.6532 0.6809 0.6862 0.667 0.7149 0.6135 0.6746 0.696 0.6589 0.6306 0.7135 0.7131 0.6842 0.7113 0.7063 0.6886 0.6364 0.6605 0.6192 0.6697 0.701 0.7136 0.7103 0.6508 0.6721 0.7102 0.6645 0.6731 0.6656 0.7049 0.6831 0.6607 0.6843 0.6818 0.6408 0.6888 0.682 0.6816 0.7028 0.6089 0.6379 0.6977 0.6873 0.6835 0.7016 0.7274 0.7031 0.682 0.6716 0.6937 0.6739 0.7177 0.6619 0.702 0.716 0.689 0.6925 0.6871 0.6791 0.7062 0.6792 0.6991 0.7291 0.6853 0.6558 0.6639 0.6765 0.7437 0.6727 0.6387 0.6888 0.743 0.6772 0.6773 0.6888 0.702 0.6875 0.6679 0.7334 0.6891 0.7215 0.5916 0.6957 0.7329 0.7294 0.6903 0.6672 0.7094 0.6625 0.6914 0.6894 0.6892 0.6417 0.6571 0.6499 0.6377 0.6472 0.7033 0.701 0.6472 0.7326 0.7411 0.6619 0.7057 0.6931 0.7073 0.6856 0.7152 0.6994 0.6615 0.691 0.7208 0.7036 0.7359 0.6306 0.734 0.7275 0.6911 0.6801 0.6787 0.6567 0.7108 0.73 0.7029 0.7122 0.729 0.6391 0.692 0.7134 0.713 0.6957 0.695 0.7003 0.7366 0.7202 0.6946 0.703 0.6649 0.7153 0.7302 0.7001 0.6664 0.6638 0.7213 0.7065 0.7091 0.6891 0.7055 0.725 0.704 0.6861 0.6596 0.6248 0.7092 0.732 0.7075 0.6827 0.6624 0.7003 0.6976 0.6861 0.7088 0.7309 0.7286 0.7064 0.6713 0.708 0.675 0.6916 0.7098 0.7225 0.6911 0.65 0.6741 0.6982 0.7111 0.7047 0.7249 0.7023 0.6959 0.7138 0.6926 0.7301 0.7373 0.6934 0.7388 0.6869 0.7105 0.7015 0.683 0.6726 0.6722 0.6722 0.7111 0.7013 0.6377 0.6547 0.6909 0.7022 0.6805 0.7106 0.6944 0.6898 0.6837 0.7121 0.6611 0.7037 0.6957 0.7171 0.6791 0.7097 0.7151 0.706 0.6984 0.6854 0.7055 0.7264 0.6825 0.6925 0.6954 0.7002 0.722 0.7429 0.7313 0.729 0.7152 0.7475 0.7285 0.6978 0.6732 0.7139 0.6981 0.7233 0.7418 0.7178 0.6753 0.6508 0.7483 0.7237 0.6941 0.7088 0.6534 0.685 0.707 0.6316 0.6668 0.6726 0.633 0.6844 0.7082 0.6795 0.7096 0.7011 0.692 0.6412 0.6552 0.7452 0.6923 0.7153 0.682 0.6911 0.7126 0.675 0.7165 0.6673 0.6467 0.6738 0.7076 0.7253 0.7252 0.7007 0.6884 0.7011 0.711 0.7005 0.6909 0.7189 0.7129 0.7277 0.74 0.7426 0.6998 0.6866 0.7149 0.741 0.7444 0.741 0.7507 0.7209 0.734 0.7201 0.7337 0.7252 0.7071 0.7454 0.7165 0.6794 0.6908 0.7287 0.7258 0.7063 0.6994 0.7248 0.6885 0.7376 0.6762 0.7207 0.6992 0.6392 0.6474 0.6443 0.661 0.7135 0.7257 0.7179 0.695 0.7007 0.7068 0.6995 0.7426 0.7277 0.6827 0.7028 0.7124 0.7156 0.702 0.7453 0.7546 0.7121 0.7108 0.7219 0.6978 0.7047 0.6987 0.705 0.7143 0.7015 0.7122 0.7265 0.71 0.6915 0.7409 0.6782 0.7178 0.742 0.7067 0.7489 0.6926 0.6874 0.7103 0.7227 0.724 0.7439 0.7243 0.7374 0.7363 0.6855 0.6992 0.7249 0.7272 0.7377 0.7203 0.7465 0.7325 0.7397 0.6779 0.6641 0.7037 0.7324 0.6951 0.7156 0.728 0.7389 0.6828 0.6912 0.6829 0.7151 0.678 0.7081 0.7246 0.7057 0.7093 0.6416 0.7324 0.6741 0.6707 0.6899 0.723 0.7087 0.7402 0.7106 0.691 0.7091 0.7254 0.6952 0.7236 0.6838 0.7071 0.732 0.6996 0.7113 0.7231 0.7035 0.6839 0.7316 0.7427 0.7383 0.7222 0.7385 0.7295 0.7164 0.6904 0.7188 0.7186 0.7328 0.7563 0.7065 0.7118 0.7029 0.7209 0.7074 0.7517 0.7257 0.7255 0.7453 0.6912 0.7305 0.7282 0.7361 0.7274 0.7062 0.7033 0.7011 0.7072 0.6897 0.7202 0.7566 0.7294 0.7236 0.7288 0.7481 0.7464 0.7003 0.7129 0.7536 0.721 0.6939 0.7364 0.713 0.7334 0.7565 0.7401 0.7483 0.7176 0.7516 0.7495 0.7261 0.731 0.7002 0.7198 0.7234 0.7046 0.7145 0.7362 0.7159 0.7047 0.6827 0.7421 0.7241 0.7169 0.7141 0.7212 0.7202 0.7011 0.7479 0.7287 0.7478 0.7283 0.7456 0.7423 0.6833 0.6811 0.6782 0.7468 0.7228 0.7359 0.7109 0.7372 0.705 0.7365 0.7349 0.7147 0.7465 0.7026 0.6816 0.7297 0.6691 0.7181 0.7247 0.736 0.7198 0.7226 0.7141 0.7047 0.7252 0.7332 0.7137 0.7295 0.6896 0.7083 0.7369 0.7461 0.7228 0.7627 0.7405 0.7256 0.7098 0.7193 0.6958 0.7179 0.7427 0.7267 0.7272 0.7216 0.6959 0.7388 0.7485 0.7371 0.7248 0.7465 0.7418 0.7352 0.7466 0.7448 0.7109 0.712 0.7148 0.731 0.6987 0.723 0.7407 0.7448 0.7259 0.7134 0.7048 0.698 0.6896 0.6774 0.6725 0.7214 0.7322 0.7314 0.6947 0.6769 0.7271 0.7429 0.7329 0.7166 0.7015 0.6804 0.6881 0.7443 0.7197 0.7211 0.7431 0.7273 0.7154 0.6901 0.6757 0.7321 0.7436 0.7385 0.6996 0.7009 0.7256 0.7045 0.6631 0.6917 0.6988 0.6899 0.7166 0.6802 0.7064 0.7158 0.7362 0.756 0.7481 0.7055 0.7475 0.7472 0.7268 0.7506 0.7461 0.7532 0.7266 0.7541 0.7303 0.7429 0.7388 0.735 0.7366 0.731 0.7403 0.733 0.7476 0.7265 0.7429 0.7452 0.7266 0.7599 0.74 0.7631 0.75 0.7351 0.7522 0.7405 0.7293 0.74 0.7514 0.749 0.7302 0.7332 0.753 0.7251 0.7396 0.7606 0.7063 0.7278 0.7052 0.7149 0.7331 0.7265 0.7323 0.7221 0.7559 0.6603 0.6885 0.7128 0.724 0.7468 0.762 0.7414 0.7514 0.7591 0.7336 0.7522 0.7416 0.761 0.752 0.7564 0.7508 0.7262 0.7085 0.7486 0.7139 0.7539 0.7493 0.7068 0.7458 0.7412 0.7522 0.7379 0.7471 0.7451 0.734 0.7513 0.7357 0.7598 0.7296 0.725 0.722 0.7367 0.7554 0.7251 0.7322 0.7161 0.7078 0.721 0.7452 0.7317 0.7272 0.7347 0.7021 0.7134 0.7231 0.6746 0.7394 0.7396 0.7161 0.7303 0.7334 0.7392 0.7384 0.7104 0.7516 0.7332 0.7504 0.7425 0.7391 0.746 0.744 0.744 0.7094 0.7488 0.7475 0.7372 0.7384 0.7335 0.7394 0.7193 0.7415 0.7265 0.7116 0.702 0.7077 0.721 0.7362 0.7133 0.7247 0.7316 0.713 0.7424 0.7557 0.7708 0.749 0.7552 0.7533 0.7386 0.7223 0.7365 0.7241 0.7155 0.714 0.7514 0.7431 0.7455 0.7136 0.7411 0.7449 0.7329 0.7563 0.7513 0.7579 0.7275 0.7565 0.7314 0.7358 0.7241 0.7298 0.7523 0.7316 0.6849 0.7474 0.7458 0.7424 0.7427 0.7155 0.7361 0.7351 0.7343 0.7478 0.7603 0.7565 0.7256 0.7317 0.7075 0.728 0.7415 0.7236 0.7122 0.6938 0.725 0.7001 0.7219 0.7 0.6937 0.7162 0.729 0.7219 0.7296 0.741 0.7513 0.7168 0.7276 0.7 0.6966 0.7391 0.7338 0.746 0.7295 0.7412 0.7204 0.7186 0.7194 
config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 51), 'alpha': (0.05, 0.05), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 5, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}
0.1667 0.2156 0.2081 0.3245 0.4052 0.3668 0.5296 0.4543 0.4503 0.5037 0.4664 0.5291 0.5434 0.4899 0.5431 0.595 0.5316 0.6064 0.6562 0.4992 0.5194 0.57 0.5077 0.5065 0.6087 0.4955 0.6752 0.467 0.5861 0.6608 0.5897 0.5793 0.5613 0.652 0.707 0.5103 0.6618 0.6702 0.6298 0.6408 0.6238 0.5657 0.6631 0.6243 0.6738 0.682 0.6103 0.6201 0.5543 0.6274 0.6254 0.6563 0.6772 0.7006 0.6459 0.6568 0.6429 0.6967 0.6686 0.6547 0.5991 0.6117 0.7195 0.5012 0.6188 0.6701 0.6658 0.6025 0.7 0.6393 0.5663 0.6926 0.6306 0.6492 0.6087 0.6574 0.7024 0.5338 0.6612 0.7203 0.7119 0.5978 0.5881 0.6564 0.6201 0.5946 0.6664 0.6383 0.6673 0.7129 0.712 0.639 0.6198 0.6444 0.6971 0.7038 0.6501 0.6497 0.6183 0.7584 0.5754 0.6335 0.7227 0.6529 0.7021 0.6769 0.7529 0.647 0.6774 0.7161 0.6777 0.6538 0.7137 0.6812 0.6112 0.6555 0.7075 0.6634 0.6586 0.64 0.638 0.6699 0.6414 0.6454 0.7055 0.7718 0.5277 0.6537 0.7185 0.6212 0.6533 0.7046 0.7085 0.6549 0.7164 0.7022 0.6214 0.7234 0.7321 0.7768 0.7122 0.7217 0.6633 0.6831 0.7084 0.6869 0.729 0.7388 0.6884 0.6866 0.7171 0.6784 0.7002 0.7342 0.6962 0.6966 0.6925 0.6569 0.7395 0.6695 0.5575 0.7393 0.5964 0.733 0.5408 0.6353 0.5999 0.606 0.7069 0.5551 0.6806 0.7705 0.669 0.6962 0.7798 0.6908 0.7234 0.7003 0.7588 0.6869 0.6553 0.7106 0.7478 0.7523 0.7152 0.6879 0.759 0.6965 0.6967 0.7665 0.6698 0.7136 0.7517 0.7223 0.7226 0.7654 0.7445 0.667 0.6647 0.7399 0.6974 0.6144 0.7557 0.6688 0.7507 0.6827 0.7148 0.6613 0.7621 0.6672 0.7309 0.7719 0.6916 0.6272 0.7098 0.7241 0.7393 0.7033 0.678 0.7161 0.6927 0.7511 0.6345 0.6902 0.6764 0.6981 0.734 0.659 0.7206 0.7649 0.6593 0.6588 0.7542 0.62 0.669 0.7738 0.738 0.6768 0.7507 0.7299 0.7768 0.724 0.7176 0.7525 0.7456 0.7552 0.7214 0.6623 0.7132 0.6993 0.7572 0.6559 0.7388 0.7018 0.745 0.7305 0.7421 0.7248 0.7185 0.6829 0.7255 0.7304 0.71 0.6938 0.7233 0.6501 0.7671 0.7338 0.7272 0.7639 0.7287 0.6225 0.7136 0.67 0.7156 0.7268 0.7212 0.6821 0.6493 0.7472 0.7302 0.7358 0.7276 0.7076 0.7191 0.6459 0.6614 0.6854 0.7462 0.6261 0.7337 0.7643 0.6214 0.6665 0.7017 0.7252 0.7669 0.7239 0.7736 0.7228 0.5918 0.7483 0.742 0.7236 0.6991 0.7316 0.7141 0.6987 0.707 0.6543 0.7802 0.7465 0.7628 0.7372 0.7147 0.6872 0.7292 0.7438 0.6808 0.6352 0.75 0.7231 0.7367 0.7737 0.7598 0.7406 0.7438 0.7478 0.7594 0.7142 0.7056 0.7157 0.7529 0.7338 0.7317 0.7586 0.7115 0.749 0.7337 0.719 0.7466 0.7375 0.73 0.7516 0.7234 0.6913 0.6931 0.6964 0.7173 0.666 0.7114 0.6636 0.7368 0.7403 0.7025 0.731 0.6893 0.7407 0.7167 0.7262 0.6847 0.6553 0.7283 0.7584 0.776 0.7671 0.7286 0.6862 0.7002 0.7178 0.6938 0.7676 0.7294 0.7495 0.7713 0.7685 0.6738 0.7432 0.7494 0.7779 0.6645 0.7286 0.7415 0.7499 0.6428 0.7636 0.7326 0.6694 0.7115 0.7513 0.7127 0.7719 0.7335 0.747 0.7153 0.7158 0.7187 0.7392 0.7573 0.786 0.7474 0.7676 0.7471 0.7369 0.777 0.7673 0.7232 0.7705 0.7293 0.7648 0.7477 0.7178 0.6849 0.763 0.7416 0.7726 0.7854 0.7024 0.7195 0.7801 0.7776 0.7561 0.7048 0.6589 0.7246 0.7445 0.7143 0.7436 0.7118 0.7728 0.7506 0.766 0.7702 0.7369 0.7574 0.7507 0.6905 0.6587 0.7032 0.741 0.7214 0.7533 0.6761 0.734 0.6868 0.6728 0.7155 0.7256 0.7423 0.7532 0.6735 0.7408 0.7583 0.7428 0.7379 0.7615 0.748 0.7455 0.6709 0.7557 0.7549 0.7036 0.7722 0.7757 0.7893 0.7703 0.7567 0.6949 0.7005 0.7509 0.7213 0.6865 0.7386 0.7115 0.6732 0.735 0.7658 0.7052 0.7115 0.7377 0.7468 0.7163 0.7684 0.7249 0.7749 0.77 0.7648 0.6871 0.7532 0.7834 0.7063 0.772 0.758 0.773 0.7783 0.7651 0.7425 0.7325 0.7555 0.7545 0.7809 0.7329 0.701 0.7394 0.7442 0.758 0.7836 0.7699 0.7156 0.7109 0.7327 0.783 0.7479 0.74 0.755 0.7311 0.7632 0.776 0.7548 0.7342 0.7406 0.766 0.7039 0.736 0.6435 0.7524 0.6796 0.7414 0.7577 0.7488 0.7436 0.7094 0.7767 0.7857 0.7513 0.7505 0.7532 0.7754 0.7179 0.7532 0.7677 0.724 0.7546 0.7625 0.7745 0.7519 0.7179 0.7498 0.7842 0.7054 0.7815 0.7569 0.697 0.7327 0.7764 0.7306 0.7659 0.73 0.7459 0.7688 0.6881 0.7602 0.7804 0.7706 0.7699 0.7496 0.7285 0.7281 0.7089 0.6937 0.7541 0.7323 0.7328 0.7544 0.7615 0.7033 0.7777 0.77 0.7644 0.7824 0.782 0.7484 0.7746 0.7172 0.7338 0.7643 0.7708 0.7776 0.7683 0.7866 0.7141 0.7514 0.754 0.7355 0.7057 0.755 0.7556 0.7702 0.7177 0.7071 0.7364 0.7641 0.7339 0.7706 0.7756 0.7669 0.7349 0.7845 0.6938 0.7729 0.7564 0.7669 0.7429 0.7568 0.7651 0.7699 0.7726 0.7378 0.7798 0.7712 0.7013 0.7555 0.7739 0.7454 0.6957 0.7738 0.7392 0.7674 0.7796 0.6136 0.7257 0.6871 0.7738 0.7518 0.7731 0.6859 0.727 0.7167 0.759 0.7627 0.7596 0.7599 0.7556 0.7098 0.7671 0.7651 0.7725 0.769 0.7681 0.7202 0.6989 0.7638 0.7755 0.7582 0.7257 0.7116 0.7506 0.7669 0.7623 0.7602 0.7378 0.7795 0.795 0.7095 0.7427 0.7694 0.7527 0.7665 0.7785 0.729 0.7724 0.7582 0.7625 0.7565 0.7774 0.7745 0.7778 0.7822 0.761 0.7705 0.702 0.7605 0.7687 0.6813 0.77 0.7782 0.7755 0.7756 0.7778 0.7325 0.7846 0.7495 0.7274 0.7165 0.7627 0.7751 0.7108 0.7363 0.7133 0.7474 0.7169 0.7358 0.7475 0.7256 0.7518 0.7624 0.7392 0.7629 0.7519 0.7662 0.6987 0.7549 0.7708 0.7512 0.7735 0.761 0.7689 0.7477 0.7589 0.7715 0.7363 0.7244 0.7517 0.7489 0.7549 0.7145 0.7822 0.7543 0.7529 0.7858 0.7407 0.7834 0.767 0.7521 0.7228 0.777 0.754 0.7692 0.7842 0.7689 0.7787 0.7863 0.774 0.7856 0.7845 0.7678 0.7708 0.7058 0.7714 0.7473 0.7367 0.764 0.7509 0.7499 0.7389 0.7387 0.7624 0.7601 0.76 0.7768 0.7786 0.7867 0.771 0.7695 0.7618 0.7761 0.754 0.7629 0.7764 0.7609 0.7476 0.7692 0.7673 0.7895 0.7411 0.7813 0.7781 0.7815 0.7736 0.7306 0.7752 0.7661 0.7868 0.784 0.7694 0.7626 0.7835 0.7591 0.7656 0.7635 0.7732 0.7689 0.7875 0.7458 0.764 0.767 0.7777 0.7466 0.7812 0.7781 0.7611 0.767 0.7836 0.7781 0.7706 0.7185 0.7138 0.768 0.7054 0.7875 0.7668 0.691 0.7182 0.7726 0.7817 0.7357 0.774 0.7846 0.7654 0.775 0.7891 0.7578 0.7679 0.7547 0.7724 0.7596 0.7278 0.7732 0.7573 0.7655 0.7384 0.735 0.7639 0.7163 0.7637 0.7826 0.7471 0.7405 0.6938 0.764 0.6894 0.7609 0.7636 0.7813 0.77 0.7729 0.7742 0.7513 0.7619 0.779 0.7801 0.7699 0.782 0.7679 0.7746 0.7859 0.7393 0.7748 0.7614 0.7659 0.7501 0.7743 0.7605 0.7541 0.7815 0.7622 0.7691 0.7505 0.7783 0.7793 0.7943 0.7362 0.7804 0.7766 0.7579 0.7738 0.7643 0.781 0.747 0.7791 0.7842 0.776 0.7456 0.7852 0.7911 0.772 0.7665 0.7611 0.7809 0.769 0.7307 0.7348 0.7666 0.7533 0.7671 0.7641 0.7531 0.7515 0.7163 0.7704 0.7157 0.7392 0.7712 0.753 0.7696 0.7388 0.7728 0.772 0.7607 0.763 0.7878 0.7555 0.7732 0.7587 0.7497 0.7854 0.7748 0.7839 0.7598 0.7812 0.7748 0.7747 0.7678 0.7721 0.7609 0.7683 0.7789 0.7352 0.7689 0.7831 0.7811 0.7763 0.7714 0.7776 0.7544 0.7648 0.7661 0.7868 0.7832 0.7519 0.7713 0.7784 0.7751 0.7846 0.7803 0.7799 0.7729 0.7747 0.7872 0.7725 0.7708 0.7777 0.764 0.7423 0.7693 0.7838 0.7557 0.7565 0.7807 0.7545 0.7643 0.7566 0.7542 0.7834 0.7817 0.7659 0.7689 0.7749 0.7856 0.7615 0.7577 0.7639 0.7712 0.7723 0.7873 0.7687 0.7749 0.7727 0.7575 0.7611 0.7711 0.7608 0.7875 0.7612 0.7544 0.7962 0.7796 0.7881 0.7867 0.7798 0.761 0.772 0.7781 0.7528 0.7344 0.7669 0.7665 0.772 0.7768 0.7791 
config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 51), 'alpha': (0.05, 0.05), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 5, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}
0.1859 0.2002 0.2159 0.318 0.2492 0.3652 0.3058 0.4528 0.3375 0.4352 0.4737 0.5531 0.4301 0.493 0.4919 0.5302 0.5252 0.3837 0.6164 0.513 0.5159 0.5693 0.5213 0.5174 0.5645 0.6176 0.6232 0.5047 0.5176 0.5844 0.5802 0.6591 0.6323 0.5597 0.6315 0.5983 0.6646 0.6102 0.5803 0.5876 0.6399 0.6387 0.6342 0.6587 0.6852 0.6221 0.6067 0.6275 0.6967 0.6843 0.6511 0.6116 0.6177 0.6371 0.6241 0.5512 0.7051 0.6752 0.6613 0.568 0.6841 0.7186 0.6386 0.6907 0.6632 0.6614 0.6472 0.6778 0.5908 0.6798 0.6755 0.6993 0.6479 0.7124 0.6415 0.685 0.6708 0.6418 0.6325 0.6271 0.6347 0.7049 0.6589 0.677 0.6256 0.5898 0.6355 0.6217 0.6963 0.6704 0.6941 0.6283 0.6942 0.6661 0.6612 0.6452 0.7114 0.6429 0.6869 0.6407 0.6758 0.6559 0.6829 0.646 0.614 0.6732 0.6386 0.6703 0.7137 0.7303 0.655 0.6197 0.7267 0.6493 0.6772 0.7022 0.7416 0.6582 0.6593 0.7175 0.6989 0.703 0.7048 0.6279 0.6421 0.7043 0.7356 0.702 0.6136 0.7112 0.7349 0.6743 0.6675 0.7324 0.6403 0.6417 0.6458 0.6822 0.5893 0.6953 0.6957 0.6209 0.6986 0.7239 0.5996 0.678 0.7049 0.684 0.649 0.6861 0.7101 0.6819 0.672 0.6165 0.7139 0.644 0.6752 0.6678 0.6279 0.7225 0.704 0.7045 0.6459 0.697 0.6818 0.7183 0.6898 0.7583 0.7025 0.6621 0.6257 0.6857 0.7237 0.6832 0.721 0.7531 0.7182 0.6569 0.6971 0.6328 0.6876 0.7363 0.7234 0.64 0.7153 0.717 0.725 0.7205 0.649 0.6213 0.6478 0.6491 0.7414 0.6952 0.6204 0.5903 0.6969 0.6822 0.6517 0.6511 0.7302 0.7131 0.6704 0.6857 0.685 0.7276 0.7013 0.6244 0.7346 0.7276 0.6654 0.7466 0.7099 0.7095 0.7023 0.6884 0.6682 0.6669 0.6813 0.7087 0.7002 0.729 0.6698 0.6739 0.6887 0.6775 0.6784 0.7405 0.7165 0.6701 0.7326 0.744 0.7359 0.6817 0.7302 0.7528 0.7068 0.7035 0.6895 0.6682 0.7278 0.6717 0.7276 0.6962 0.7112 0.7645 0.6944 0.6301 0.6768 0.6784 0.6528 0.7117 0.6651 0.6773 0.7338 0.7266 0.643 0.6412 0.6627 0.6767 0.7262 0.7247 0.6909 0.6848 0.7427 0.7304 0.7597 0.6996 0.6755 0.7031 0.6797 0.6913 0.7419 0.7027 0.7166 0.7149 0.7148 0.7547 0.7334 0.7415 0.7535 0.6415 0.6922 0.6918 0.754 0.6669 0.6997 0.7284 0.6691 0.7008 0.7001 0.7111 0.7286 0.6543 0.7157 0.7612 0.6364 0.7173 0.6808 0.7409 0.7266 0.6716 0.6746 0.6444 0.6997 0.689 0.6663 0.6883 0.7439 0.7217 0.7023 0.7155 0.6936 0.7528 0.7117 0.7307 0.7398 0.7358 0.73 0.7082 0.735 0.6926 0.714 0.6941 0.6425 0.7233 0.7583 0.7041 0.7103 0.7262 0.7002 0.7046 0.6439 0.7419 0.7025 0.7221 0.7455 0.7474 0.6567 0.7272 0.6969 0.7476 0.7677 0.7265 0.739 0.6795 0.7493 0.7164 0.77 0.7016 0.7397 0.738 0.7538 0.7153 0.7613 0.7042 0.7293 0.7249 0.7064 0.7505 0.6703 0.6619 0.7463 0.6139 0.6677 0.7045 0.7113 0.7454 0.7327 0.6903 0.7092 0.6891 0.7289 0.7235 0.7365 0.7255 0.7117 0.6512 0.7138 0.7117 0.7529 0.7028 0.698 0.7053 0.6816 0.7434 0.7412 0.7266 0.7229 0.7273 0.7407 0.7308 0.7189 0.6877 0.7111 0.7644 0.7227 0.698 0.7012 0.7329 0.6805 0.7486 0.732 0.7108 0.7333 0.7377 0.668 0.7146 0.7453 0.7284 0.7473 0.7462 0.7083 0.7083 0.7266 0.7241 0.7175 0.7169 0.7079 0.6741 0.6695 0.719 0.7411 0.7599 0.7558 0.7526 0.746 0.749 0.7243 0.7558 0.7146 0.7473 0.7161 0.6475 0.6751 0.7181 0.7243 0.7418 0.7211 0.7327 0.7431 0.6594 0.6944 0.7068 0.6922 0.6824 0.7506 0.7141 0.751 0.7576 0.7479 0.7373 0.7496 0.7543 0.696 0.7289 0.7306 0.74 0.7075 0.7275 0.7361 0.6881 0.7618 0.7527 0.7591 0.7478 0.7154 0.7001 0.734 0.7382 0.7162 0.7386 0.6801 0.7107 0.675 0.7093 0.7366 0.6965 0.7485 0.737 0.7365 0.7281 0.7241 0.717 0.7225 0.7238 0.6689 0.7217 0.677 0.6509 0.7599 0.764 0.7552 0.6629 0.7568 0.7492 0.7466 0.7539 0.7618 0.7422 0.748 0.7491 0.7577 0.7368 0.7223 0.7221 0.7535 0.6951 0.7268 0.7417 0.7484 0.7031 0.7138 0.7137 0.7224 0.7137 0.732 0.6991 0.7156 0.747 0.7299 0.7366 0.7367 0.7402 0.7467 0.7707 0.767 0.7105 0.704 0.7615 0.7363 0.7489 0.6906 0.7109 0.7728 0.7403 0.6858 0.68 0.7247 0.7404 0.6882 0.7458 0.7266 0.6727 0.6978 0.7291 0.7092 0.663 0.6943 0.6912 0.7508 0.7461 0.7129 0.6984 0.7003 0.7332 0.7175 0.7321 0.7446 0.7171 0.7165 0.7354 0.776 0.6962 0.7405 0.744 0.7699 0.7347 0.7063 0.6798 0.7443 0.7305 0.7635 0.7648 0.731 0.7389 0.7097 0.7153 0.7255 0.7099 0.739 0.7061 0.7111 0.7401 0.6841 0.7519 0.7043 0.7579 0.7237 0.7396 0.7561 0.7232 0.7327 0.7656 0.7282 0.6991 0.7136 0.7287 0.6985 0.6853 0.7261 0.7328 0.7444 0.7415 0.7412 0.7265 0.7752 0.6949 0.7154 0.6442 0.7416 0.7015 0.7502 0.7288 0.752 0.6225 0.7196 0.7358 0.7409 0.7473 0.7658 0.7582 0.7596 0.7237 0.7061 0.7313 0.7476 0.766 0.7049 0.6988 0.7259 0.7594 0.716 0.7445 0.7406 0.755 0.7415 0.74 0.7357 0.7429 0.7707 0.7291 0.7644 0.7126 0.648 0.7472 0.7488 0.6915 0.6838 0.7603 0.7717 0.7088 0.7509 0.7545 0.6989 0.7274 0.7528 0.732 0.736 0.7481 0.762 0.7598 0.7574 0.7484 0.7309 0.7231 0.7444 0.7612 0.7634 0.7502 0.7411 0.7414 0.7406 0.7526 0.7619 0.6878 0.771 0.7154 0.7691 0.7634 0.7766 0.7102 0.7469 0.6822 0.7391 0.7145 0.7353 0.7654 0.7471 
config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 51), 'alpha': (0.05, 0.05), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 5, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}
0.1867 0.2664 0.3883 0.4201 0.3589 0.4386 0.4298 0.5115 0.4169 0.4179 0.4126 0.5208 0.5144 0.5588 0.4608 0.5378 0.5097 0.4723 0.575 0.5285 0.4918 0.55 0.5642 0.5929 0.6739 0.6629 0.6199 0.578 0.604 0.5552 0.6531 0.5375 0.6577 0.6417 0.6632 0.5584 0.5406 0.6865 0.6151 0.6318 0.6258 0.708 0.6696 0.6347 0.6968 0.5837 0.5405 0.6328 0.6587 0.6109 0.6284 0.6715 0.6473 0.6667 0.7471 0.6402 0.7169 0.6591 0.6942 0.6623 0.6737 0.6612 0.6967 0.6588 0.7297 0.6755 0.6675 0.6129 0.6851 0.6621 0.6919 0.682 0.7039 0.6513 0.6872 0.7114 0.6736 0.6953 0.5831 0.7341 0.7326 0.6888 0.6718 0.6753 0.6286 0.7423 0.7074 0.7154 0.7164 0.6843 0.6784 0.7262 0.6976 0.7258 0.665 0.6722 0.5887 0.7 0.7383 0.6968 0.7075 0.6947 0.7276 0.7025 0.6874 0.7166 0.7333 0.7221 0.7283 0.6874 0.7149 0.6821 0.6802 0.6854 0.6271 0.6449 0.686 0.7283 0.6511 0.6368 0.7451 0.7732 0.7115 0.7475 0.7605 0.7039 0.7427 0.6944 0.722 0.7452 0.6921 0.7423 0.6909 0.7177 0.7348 0.746 0.7467 0.7719 0.7286 0.6246 0.767 0.6881 0.7544 0.7068 0.6619 0.6822 0.7346 0.759 0.7257 0.6803 0.7317 0.7652 0.681 0.7052 0.7174 0.661 0.7006 0.6895 0.697 0.6737 0.7501 0.6881 0.668 0.7421 0.7306 0.7656 0.6472 0.7374 0.6942 0.7502 0.6749 0.7002 0.7316 0.7234 0.7848 0.7223 0.7558 0.7525 0.7295 0.6893 0.7054 0.6916 0.7089 0.7296 0.7604 0.665 0.759 0.691 0.6406 0.7221 0.7275 0.7137 0.7061 0.7225 0.6401 0.7458 0.771 0.6762 0.7084 0.7868 0.7482 0.7329 0.6809 0.7319 0.777 0.7702 0.7719 0.7494 0.7335 0.7253 0.7453 0.7429 0.6927 0.7558 0.7602 0.7356 0.7336 0.6506 0.7196 0.7212 0.6871 0.7775 0.7512 0.6837 0.6648 0.725 0.762 0.7619 0.7244 0.7625 0.7794 0.7142 0.7285 0.7334 0.7383 0.7769 0.642 0.7064 0.7328 0.7448 0.7724 0.7363 0.7387 0.7938 0.7823 0.7322 0.7211 0.7695 0.7156 0.7302 0.6979 0.7838 0.7419 0.785 0.6731 0.797 0.7553 0.7658 0.7528 0.7369 0.7298 0.7289 0.7197 0.7695 0.7377 0.6908 0.7077 0.7264 0.7839 0.7471 0.7574 0.7503 0.7441 0.7164 0.7433 0.6613 0.7462 0.7451 0.764 0.739 0.7265 0.7627 0.7575 0.6565 0.7311 0.7248 0.7668 0.7278 0.7567 0.7695 0.7406 0.7524 0.7641 0.6765 0.7743 0.7621 0.7099 0.7749 0.7829 0.7583 0.6985 0.7865 0.7656 0.78 0.7594 0.7382 0.7595 0.6926 0.7862 0.759 0.7789 0.7193 0.7517 0.7284 0.747 0.7642 0.6827 0.7795 0.72 0.7681 0.7659 0.7402 0.7382 0.7792 0.7322 
config:{'task_name': <TaskName.FMNIST: 3>, 'server_num': 1, 'client_num': 100, 'data_num_range': (10, 51), 'alpha': (0.05, 0.05), 'sampling_frac': 0.2, 'data_path': './data/', 'budget': 10000000, 'global_epoch_num': 1000, 'group_epoch_num': 5, 'local_epoch_num': 2, 'regroup_interval': 10000, 'lr_interval': 1000, 'lr': 0.001, 'batch_size': 5, 'device': 'cuda', 'train_method': <TrainMethod.SGD: 1>, 'selection_mode': <SelectionMode.RANDOM: 10>, 'aggregation_option': <AggregationOption.WEIGHTED_AVERAGE: 1>, 'grouping_mode': <GroupingMode.RANDOM: 2>, 'max_group_cv': 1.0, 'min_group_size': 5, 'log_interval': 1, 'result_dir': './exp_data/grouping/rg_rs/', 'test_mark': '_fmnist', 'comment': ''}
0.1963 0.136 0.1901 0.3253 0.3515 0.3307 0.3259 0.3437 0.411 0.4954 0.3953 0.4277 0.5563 0.4247 0.5086 0.4634 0.4734 0.547 0.6084 0.5596 0.5461 0.6372 0.5363 0.5191 0.5712 0.6224 0.5966 0.5594 0.6903 0.6481 0.5928 0.5832 0.6437 0.6078 0.6026 0.6592 0.6332 0.7002 0.6302 0.5562 0.6523 0.6695 0.6586 0.5846 0.6519 0.6136 0.6409 0.6332 0.6927 0.6861 0.7 0.615 0.662 0.5613 0.5605 0.7124 0.6127 0.6515 0.6036 0.6328 0.6006 0.6615 0.6509 0.664 0.553 0.7015 0.6444 0.6476 0.6203 0.6629 0.6346 0.5809 0.6813 0.7074 0.5855 0.7215 0.7017 0.6252 0.6212 0.6896 0.6373 0.7127 0.6842 0.729 0.6621 0.698 0.6476 0.6862 0.683 0.6103 0.721 0.7162 0.6474 0.7277 0.6558 0.6638 0.6732 0.6545 0.6702 0.6893 0.7251 0.7187 0.6882 0.6957 0.6498 0.6728 0.6301 0.6815 0.7275 0.6636 0.7292 0.7062 0.6637 0.7156 0.6843 0.6824 0.6566 0.6995 0.6629 0.6471 0.66 0.7313 0.6681 0.6753 0.6585 0.6101 0.6618 0.7256 0.6911 0.6871 0.7067 0.6851 0.7191 0.7278 0.7276 0.6492 0.7199 0.6471 0.6711 0.6109 0.696 0.692 0.6747 0.6865 0.727 0.662 0.6892 0.6802 0.6811 0.7252 0.693 0.7255 0.6641 0.7068 0.6805 0.6787 0.7371 0.6886 0.7091 0.6815 0.6838 0.6555 0.7291 0.6497 0.6974 0.7141 0.7176 0.7041 0.6866 0.6537 0.6972 0.7451 0.7208 0.6511 0.7526 0.6218 0.6285 0.7438 0.7052 0.7056 0.7225 0.6961 0.7207 0.6991 0.7192 0.6835 0.703 0.6759 0.7108 0.739 0.6903 0.7368 0.6483 0.6704 0.6495 0.6674 0.6834 0.6983 0.6987 0.6393 0.7504 0.7334 0.6942 0.6626 0.6998 0.7347 0.7334 0.6282 0.7568 0.6809 0.7261 0.7213 0.7055 0.7244 0.649 0.7095 0.7135 0.6977 0.721 0.7371 0.6951 0.6518 0.7238 0.6593 0.7259 0.748 0.7 0.6908 0.7165 0.6858 0.7045 0.7079 0.6783 0.7367 0.7006 0.7223 0.6914 0.6353 0.7022 0.7022 0.7341 0.7142 0.6573 0.6547 0.7329 0.6565 0.6474 0.704 0.7343 0.7052 0.6911 0.7059 0.6878 0.7254 0.6951 0.6613 0.6881 0.7406 0.6665 0.729 0.7099 0.7311 0.764 0.6723 0.6254 0.7045 0.6803 0.6719 0.7181 0.708 0.7385 0.7055 0.7345 0.7306 0.7337 0.6673 0.6582 0.687 0.6397 0.724 0.6821 0.7392 0.7113 0.6525 0.6936 0.706 0.7303 0.6556 0.6514 0.7125 0.7157 0.7196 0.6996 0.7485 0.7403 0.7342 0.7018 0.7331 0.7226 0.691 0.7339 0.7403 0.7141 0.6926 0.6958 0.7151 0.7067 0.6688 0.7572 0.6745 0.7144 0.7182 0.7243 0.7352 0.7018 0.7333 0.7526 0.6797 0.6607 0.7115 0.6873 0.6844 0.7741 0.6518 0.7135 0.7131 0.7547 0.7509 0.7341 0.7525 0.7278 0.7035 0.6764 0.698 0.7116 0.7357 0.6867 0.7117 0.7431 0.7509 0.748 0.7229 0.7596 0.762 0.7119 0.7046 0.7074 0.7161 0.7549 0.7217 0.7251 0.717 0.7408 0.7418 0.7765 0.6741 0.7455 0.716 0.737 0.7249 0.7069 0.6703 0.7364 0.6544 0.6858 0.6704 0.6671 0.7181 0.7027 0.7513 0.7448 0.7349 0.7157 0.7362 0.734 0.7014 0.7129 0.7427 0.7111 0.6475 0.7335 0.7501 0.7445 0.6846 0.7153 0.6943 0.7338 0.6954 0.6778 0.7378 0.6982 0.7374 0.7332 0.7304 0.7475 0.6645 0.7183 0.7289 0.7077 0.7046 0.7283 0.6842 0.6875 0.7411 0.7165 0.7058 0.7502 0.6756 0.7205 0.7059 0.7322 0.6733 0.6833 0.7261 0.7229 0.7418 0.7226 0.6819 0.6981 0.7113 0.7155 0.7118 0.703 0.7572 0.706 0.7271 0.7345 0.7432 0.6973 0.7495 0.6973 0.733 0.7216 0.7582 0.7614 0.7312 0.7513 0.7633 0.7456 0.6975 0.7155 0.7677 0.7186 0.7372 0.7466 0.7289 0.7167 0.7479 0.6983 0.7292 0.7463 0.7269 0.7111 0.7174 0.6929 0.7518 0.6377 0.7477 0.6882 0.7172 0.7582 0.7208 0.7489 0.7417 0.7423 0.7263 0.7407 0.6835 0.7148 0.757 0.7266 0.7407 0.6819 0.7499 0.7058 0.6927 0.7402 0.7269 0.6963 0.7511 0.7262 0.7257 0.7632 0.7495 0.7334 0.7193 0.7701 0.7341 0.7312 0.6824 0.7124 0.7551 0.6881 0.7089 0.7107 0.748 0.6926 0.7044 0.7041 0.6942 0.6816 0.7226 0.7553 0.7363 0.7019 0.7048 0.7381 0.7518 0.7379 0.7318 0.7347 0.7641 0.737 0.7255 0.7437 0.7155 0.7322 0.7246 0.7142 0.723 0.6154 0.7338 0.7433 0.7456 0.7162 0.7259 0.6919 0.7022 0.7381 0.7273 0.7004 0.683 0.7569 0.7029 0.7172 0.7647 0.7321 0.7364 0.7369 0.7402 0.7157 0.7654 0.7416 0.7619 0.7248 0.7487 0.764 0.7169 0.7377 0.6986 0.7082 0.7387 0.6977 0.738 0.7586 0.7284 0.7603 0.752 0.7242 0.7469 0.751 0.716 0.7278 0.7044 0.7548 0.6711 0.7011 0.7156 0.7456 0.7153 0.7576 0.709 0.7311 0.7434 0.7361 0.7462 0.7314 0.7463 0.7395 0.7346 0.7525 0.768 0.7548 0.7386 0.7421 0.7236 0.7273 0.7687 0.7128 0.6928 0.7352 0.7434 0.7503 0.7432 0.7321 0.761 0.6913 0.7321 0.7565 0.7098 0.7281 0.723 0.7212 0.7298 0.6795 0.7786 0.7812 0.703 0.7359 0.7076 0.699 0.7383 0.7459 0.71 0.7617 0.7489 0.766 0.7694 0.7441 0.7476 0.7123 0.7601 0.68 0.7302 0.7355 0.7347 0.7352 0.75 0.7102 0.7586 0.7624 0.7519 0.755 0.776 0.6762 0.7288 0.7569 0.7567 0.758 0.7382 0.7575 0.7082 0.7127 0.7417 0.7538 0.7503 0.7214 0.6944 0.7047 0.7378 0.7313 0.7294 0.7507 0.713 0.7429 0.7505 0.7276 0.7132 0.7572 0.7571 0.7476 0.7308 0.6929 0.7407 0.7476 0.7508 0.751 0.7187 0.7022 0.7169 0.7194 0.7528 0.6793 0.717 0.7382 0.71 0.7293 0.7401 0.7404 0.76 0.7456 0.7535 0.7545 0.7382 0.7673 0.7289 0.7559 0.7689 0.7383 0.7331 0.7492 0.74 0.7259 0.7085 0.7647 0.724 0.7615 0.7608 0.7178 0.7598 0.7596 0.7523 0.7141 0.744 0.7552 0.7588 0.7547 0.7204 0.7179 0.7326 0.7321 0.7378 0.729 0.724 0.7304 0.7334 0.7561 0.7604 0.7393 0.7356 0.6935 0.75 0.7503 0.7296 0.7494 0.7689 0.7462 0.7585 0.7561 0.7577 0.7371 0.739 0.7451 0.7492 0.76 0.7429 0.7145 0.7273 0.7428 0.7519 0.7114 0.7594 0.7423 0.7453 0.7337 0.7495 0.7355 0.736 0.7656 0.7721 0.7426 0.7237 0.7461 0.7546 0.7569 0.7312 0.7519 0.7404 0.7624 0.6126 0.7101 0.7642 0.7083 0.7259 0.6981 0.756 0.7226 0.7491 0.7487 0.7511 0.7068 0.7371 0.7454 0.7594 0.7224 0.7518 0.7444 0.6929 0.7134 0.7267 0.7647 0.7216 0.6894 0.7216 0.761 0.7584 0.7641 0.7586 0.7644 0.7622 0.7174 0.7626 0.7352 0.7392 0.7381 0.7458 0.7386 0.7567 0.7396 0.7571 0.7467 0.7435 0.7348 0.7363 0.7716 0.7494 0.7189 0.744 0.763 0.7402 0.7304 0.7536 0.7412 0.7706 0.7071 0.7576 0.7716 0.7292 0.7677 0.7528 0.7332 0.7388 0.7366 0.7625 0.7383 0.7468 0.7601 0.7626 0.7604 0.7615 0.7621 0.7644 0.7425 0.7692 0.7287 0.7646 0.7672 0.7112 0.7565 0.7746 0.7586 0.7567 0.7387 0.7668 0.7697 0.7386 0.7486 0.7041 0.7458 0.7697 0.7733 0.7532 0.7586 0.7454 0.764 0.7355 0.7593 0.7622 0.766 0.7464 0.7736 0.7324 0.7778 0.7466 0.733 0.7664 0.737 0.7427 0.7394 0.7127 0.7376 0.7015 0.6874 0.7617 0.7561 0.7481 0.7626 0.7622 0.7636 0.7643 0.7509 0.6984 0.7344 0.7456 0.7566 0.7533 0.7486 0.7566 0.742 0.7352 0.7382 0.7333 0.7307 0.7469 0.7714 0.7385 0.7627 0.7743 0.7471 0.7109 0.7466 0.7454 0.7384 0.7581 0.7511 0.7245 0.7695 0.7648 0.7694 0.7661 0.7462 0.7192 0.7599 0.7675 0.7314 0.7583 0.7485 0.7271 0.7214 0.7479 0.7662 0.7821 0.7093 0.7457 0.7615 0.7591 0.7764 0.7288 0.7838 0.7626 0.7612 0.7592 0.7754 0.7571 0.7679 0.7546 0.7577 0.7499 0.7559 0.7029 0.7536 0.7054 0.7443 0.733 0.7714 0.7562 0.7588 0.7575 0.7441 0.7455 0.7644 0.7434 0.7298 0.7448 0.7425 0.7264 0.7274 0.7523 0.7478 0.7632 0.7605 0.7519 0.7496 0.7564 0.7614 0.7052 0.7037 0.7531 0.7366 0.7542 0.7067 0.7545 0.7244 0.7144 0.7265 0.7248 0.7518 0.75 0.7455 0.7571 0.7612 0.7694 0.7678 0.769 0.6988 0.7587 0.7588 0.7544 0.7553 0.7324 0.7229 0.7576 0.7329 0.7579 0.7491 0.7366 0.7583 0.7562 0.7693 0.7632 